{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PM-OpidNr-2t"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VD6FmmptNgi",
    "outputId": "7ce67015-39d1-45d4-eacf-eddb26355488"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1bfe36213b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_IXCcwxLytwu"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') #required for imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xq-hPW8IzSOg"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The SwiGLU activation function,\n",
    "from \"GLU Variants Improve Transformer\" (Shazeer, 2020).\n",
    "\n",
    "From the paper:\n",
    "'We offer no explanation as to why these architectures seem to work;\n",
    "we attribute their success, as all else, to __divine benevolence__.'\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SwiGLU(nn.Module):\n",
    "    \"\"\"\n",
    "    The SwiGLU activation function as proposed by Noam Shazeer.\n",
    "\n",
    "    This module implements the SwiGLU function defined as:\n",
    "    FFN_SwiGLU(x, W, V, W2) = (Swish_{1}(xW) ⊙ (xV))W2\n",
    "    where ⊙ denotes the Hadamard product and Swish_{1} is the Swish function with β=1.\n",
    "\n",
    "    Note: The Swish function with β=1 is equivalent to PyTorch's SiLU function.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Input and output dimension.\n",
    "        h_dim (int): Hidden dimension.\n",
    "        bias (bool, optional): If false, additive biases will not be learned.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, h_dim, bias=False):\n",
    "        super().__init__()\n",
    "        self.w = nn.Linear(dim, h_dim, bias=bias)\n",
    "        self.v = nn.Linear(dim, h_dim, bias=bias)\n",
    "        self.w2 = nn.Linear(h_dim, dim, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.silu(self.w(x)) * self.v(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "a-i6Ahw0uV1d"
   },
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def get_hankel(n: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generates a Hankel matrix Z, as defined in Equation (3) of the paper.\n",
    "\n",
    "    This special matrix is used for the spectral filtering in the Spectral\n",
    "    Transform Unit (STU).\n",
    "\n",
    "    Args:\n",
    "        n (int): Size of the square Hankel matrix.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Hankel matrix Z of shape [n, n].\n",
    "    \"\"\"\n",
    "    i = torch.arange(1, n + 1)\n",
    "    s = i[:, None] + i[None, :]\n",
    "    Z = 2.0 / (s**3 - s)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mlmAFn2_uaft"
   },
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def get_top_eigh(\n",
    "    n: int, K: int, use_hankel_L: bool, device: torch.device\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Returns the top K eigenvalues and eigenvectors of the Hankel matrix Z.\n",
    "\n",
    "    These eigenvalues and eigenvectors are used to construct the spectral\n",
    "    filters for the STU model, as described in Section 3 of the paper.\n",
    "\n",
    "    Args:\n",
    "        n (int): Size of the Hankel matrix.\n",
    "        K (int): Number of top eigenvalues/eigenvectors to return.\n",
    "        use_hankel_L (bool): If True, use the alternative Hankel matrix Z_L.\n",
    "        device (torch.device): Computation device (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        tuple[torch.Tensor, torch.Tensor]:\n",
    "            - sigma: Top K eigenvalues [K]\n",
    "            - phi: The corresponding eigenvectors [n, K]\n",
    "    \"\"\"\n",
    "    # Z = get_hankel_L(n).to(device) if use_hankel_L else get_hankel(n).to(device)\n",
    "    Z = get_hankel(n).to(device)\n",
    "    sigma, phi = torch.linalg.eigh(Z)\n",
    "    return sigma[-K:], phi[:, -K:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vBUguWnnsI1z"
   },
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def shift(u: torch.Tensor, k: int = 1) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Rolls the time axis forward by k steps to align the input u_{t-k} with u_t.\n",
    "    This effectively removes the last k time steps of the input tensor.\n",
    "\n",
    "    This function implements the time shifting functionality needed for\n",
    "    the autoregressive component in Equation 4 of the STU model (Section 3).\n",
    "\n",
    "    Args:\n",
    "        u (torch.Tensor): An input tensor of shape [bsz, sl, K, d].\n",
    "        k (int): Number of time steps to shift. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Shifted tensor of shape [bsz, sl, K, d].\n",
    "    \"\"\"\n",
    "    if k == 0:\n",
    "        return u\n",
    "    shifted = torch.roll(u, shifts=k, dims=1)\n",
    "    shifted[:, :k] = 0\n",
    "    return shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0kjpNlHKsD3Q"
   },
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def compute_ar_u(M_u: torch.Tensor, u: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the autoregressive component of the STU model with respect to\n",
    "    the input, as described in Equation (4) of Section 3.\n",
    "\n",
    "    This function implements the sum of M^u_i u_{t+1-i} from i=1 to\n",
    "    (more generally) k_u (in the paper, it was up until i=3).\n",
    "\n",
    "    Args:\n",
    "        M_u (torch.Tensor): Input weight matrices of shape (d_out, k_u, d_in)\n",
    "        u (torch.Tensor): Input tensor of shape (bsz, sl, d_in)\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Autoregressive component w.r.t. input of shape (bsz, sl, d_out)\n",
    "    \"\"\"\n",
    "    k_u = M_u.shape[1]\n",
    "\n",
    "    # Sum M^u_i \\hat_{u}_{t+1-i} from i=1 to i=k_u\n",
    "    u_shifted = torch.stack([shift(u, i) for i in range(k_u)], dim=1)\n",
    "    ar_u = torch.einsum(\"bksd,dki->bsi\", u_shifted, M_u)\n",
    "\n",
    "    return ar_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xxwcxaYex3-K"
   },
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def compute_ar_y(M_y: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the autoregressive component of the AR-STU model with respect to\n",
    "    the output, as described in Equation (6) of Section 5.\n",
    "\n",
    "    This function implements the sum of M^y_i y_{t-i} from i=1 to i=k_y.\n",
    "\n",
    "    Args:\n",
    "        M_y: Output weight matrices of shape (d_out, k_y, d_out)\n",
    "        y: Predictions (bsz, sl, d_out)\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Autoregressive component w.r.t. output of shape (bsz, sl, d_out)\n",
    "    \"\"\"\n",
    "    # k_y = M_y.shape[0]\n",
    "\n",
    "    # # Sum M^y_i \\hat_{y}_{t-i} from i=1 to i=k_y\n",
    "    # y_shifted = torch.stack([shift(y, i + 1) for i in range(k_y)], dim=1)\n",
    "    # ar_y = torch.einsum(\"bksd,kod->bso\", y_shifted, M_y)\n",
    "    # return ar_y\n",
    "    k, d_out, _ = M_y.shape\n",
    "    bsz, sl, _ = y.shape\n",
    "\n",
    "    # Initialize carry buffer and output tensor\n",
    "    carry = torch.zeros((bsz, k, d_out), device=y.device)\n",
    "    ys = torch.zeros((bsz, sl, d_out), device=y.device)\n",
    "\n",
    "    # Process each timestep\n",
    "    for t in range(sl):\n",
    "        # Current input: (bsz, d_out)\n",
    "        x = y[:, t]\n",
    "\n",
    "        # Compute AR component: (bsz, d_out)\n",
    "        output = torch.einsum('dko,bkd->bo', M_y, carry) + x\n",
    "\n",
    "        # Store output\n",
    "        ys[:, t] = output\n",
    "\n",
    "        # Update carry buffer\n",
    "        carry = torch.cat([output.unsqueeze(1), carry[:, :-1]], dim=1)\n",
    "\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "3qBxujdSAyAG"
   },
   "outputs": [],
   "source": [
    "def compute_ar(M_y, M_u, u):\n",
    "    \"\"\"\n",
    "    Computes both autoregressive components of the STU model\n",
    "    as described in Equation (4) of Section 3.\n",
    "\n",
    "    Args:\n",
    "        M_y (torch.Tensor): Input weight matrices of shape (d_out, k_y, d_in)\n",
    "        M_u (torch.Tensor): Input weight matrices of shape (d_out, k_u, d_in)\n",
    "        u (torch.Tensor): Input tensor of shape (B, L, d_in)\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Autoregressive component w.r.t. input of shape (B, L, d_out)\n",
    "    \"\"\"\n",
    "    bsz, seq_len, _ = u.shape\n",
    "    D, k_y, _ = M_y.shape\n",
    "    output_list = []  # Store outputs for each timestep\n",
    "\n",
    "    for t in range(seq_len):\n",
    "        terms = []  # Collect all terms for this timestep\n",
    "\n",
    "        # AR component\n",
    "        for i in range(1, k_y + 1):\n",
    "            if t - i >= 0:\n",
    "                M_i = M_y[:, i-1]\n",
    "                y_prev = output_list[t-i]\n",
    "                terms.append(y_prev @ M_i.T)\n",
    "\n",
    "        # Control component\n",
    "        if M_u is not None:\n",
    "            k_u = M_u.shape[1]\n",
    "            for i in range(1, k_u + 1):\n",
    "                if t + 1 - i >= 0 and t + 1 - i < seq_len:\n",
    "                    u_prev = u[:, t+1-i]\n",
    "                    terms.append(u_prev @ M_u[:, i-1].T)\n",
    "\n",
    "        # Sum all terms for this timestep\n",
    "        if terms:\n",
    "            output_list.append(sum(terms))\n",
    "        else:\n",
    "            output_list.append(torch.zeros(bsz, D, device=u.device))\n",
    "\n",
    "    # Stack all timesteps\n",
    "    return torch.stack(output_list, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uOQUSSFMq7lZ",
    "outputId": "cdb5f2f4-3eb9-4f3a-8762-6dc05d672b55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "@torch.jit.script\n",
    "def compute_ar_y(M_y: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the autoregressive component of the AR-STU model.\n",
    "\n",
    "    Args:\n",
    "        M_y: Output weight matrices of shape (d_out, k_y, d_out)\n",
    "        y: Predictions (bsz, sl, d_out)\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Autoregressive component (bsz, sl, d_out)\n",
    "    \"\"\"\n",
    "    k, d_out, _ = M_y.shape\n",
    "    bsz, sl, _ = y.shape\n",
    "\n",
    "    # Initialize carry buffer and output tensor\n",
    "    carry = torch.zeros((bsz, k, d_out), device=y.device)\n",
    "    ys = torch.zeros((bsz, sl, d_out), device=y.device)\n",
    "\n",
    "    # Process each timestep\n",
    "    for t in range(sl):\n",
    "        # Current input: (bsz, d_out)\n",
    "        x = y[:, t]\n",
    "\n",
    "        # Compute AR component: (bsz, d_out)\n",
    "        output = torch.einsum('kdo,bkd->bo', M_y, carry) + x\n",
    "\n",
    "        # Store output\n",
    "        ys[:, t] = output\n",
    "\n",
    "        # Update carry buffer\n",
    "        carry = torch.cat([output.unsqueeze(1), carry[:, :-1]], dim=1)\n",
    "\n",
    "    return ys\n",
    "\n",
    "def test_compute_ar_y():\n",
    "    \"\"\"Test the autoregressive computation\"\"\"\n",
    "    k_y, d_out = 2, 3\n",
    "    bsz, sl = 4, 5\n",
    "\n",
    "    # Test shapes\n",
    "    M_y = torch.randn(k_y, d_out, d_out)\n",
    "    y = torch.randn(bsz, sl, d_out)\n",
    "    output = compute_ar_y(M_y, y)\n",
    "    assert output.shape == (bsz, sl, d_out)\n",
    "\n",
    "    # Test first timestep (should just be input)\n",
    "    assert torch.allclose(output[:, 0], y[:, 0])\n",
    "\n",
    "    # Test with identity matrices\n",
    "    M_y = torch.eye(d_out).unsqueeze(0).repeat(k_y, 1, 1)\n",
    "    y = torch.ones(bsz, sl, d_out)\n",
    "    output = compute_ar_y(M_y, y)\n",
    "    assert output.shape == (bsz, sl, d_out)\n",
    "\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "# Run tests\n",
    "test_compute_ar_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "aopSEWFCx5Zw"
   },
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def nearest_power_of_2(x: int) -> int:\n",
    "    \"\"\"\n",
    "    Returns the smallest power of 2 that is greater than or equal to x.\n",
    "    If x is already a power of 2, it returns x itself.\n",
    "    Otherwise, it returns the next higher power of 2.\n",
    "\n",
    "    Args:\n",
    "        x (int): The input integer.\n",
    "\n",
    "    Returns:\n",
    "        int: The smallest power of 2 that is greater than or equal to x.\n",
    "    \"\"\"\n",
    "    s = bin(x)\n",
    "    s = s.lstrip(\"-0b\")\n",
    "    length = len(s)\n",
    "    return 1 << (length - 1) if x == 1 << (length - 1) else 1 << length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "UwsOdhjux8Q4"
   },
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def conv(u: torch.Tensor, phi: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Implements the FFT convolution of the input sequences into the Hankel\n",
    "    spectral basis, as described in Section 3 of the paper.\n",
    "\n",
    "    This function computes U⁺_{t,k} and U⁻_{t,k}, which are the positive and\n",
    "    negative featurizations of the input sequence, respectively.\n",
    "\n",
    "    Args:\n",
    "        u (torch.Tensor): Input of shape [bsz, sl, d].\n",
    "        phi (torch.Tensor): Top K eigenvectors of shape [sl, K].\n",
    "\n",
    "    Returns:\n",
    "        tuple[torch.Tensor, torch.Tensor]: Feature tensors U⁺ and U⁻ of shape [bsz, sl, K, d].\n",
    "    \"\"\"\n",
    "    bsz, sl, d = u.shape\n",
    "    _, K = phi.shape\n",
    "\n",
    "    # Round sequence length to the nearest power of 2 for efficient convolution\n",
    "    n = nearest_power_of_2(sl * 2 - 1)\n",
    "\n",
    "    # Add bsz and d dims to phi and u and expand to the return shape\n",
    "    phi = phi.view(1, -1, K, 1).expand(bsz, -1, K, d)\n",
    "    u = u.view(bsz, -1, 1, d).expand(bsz, -1, K, d)\n",
    "\n",
    "    # Compute U⁺\n",
    "    V = torch.fft.rfft(phi, n=n, dim=1)\n",
    "    U = torch.fft.rfft(u, n=n, dim=1)\n",
    "    U_plus = torch.fft.irfft(V * U, n=n, dim=1)[:, :sl]\n",
    "\n",
    "    # Generate alternating signs tensor, (-1)^i of length sl, match dims of u\n",
    "    alt = torch.ones(sl, device=u.device)\n",
    "    alt[1::2] = -1  # Replace every other element with -1, starting from index 1\n",
    "    alt = alt.view(1, sl, 1, 1).expand_as(u)\n",
    "\n",
    "    # Compute U⁻\n",
    "    u_alt = u * alt\n",
    "    U_alt = torch.fft.rfft(u_alt, n=n, dim=1)\n",
    "    U_minus = torch.fft.irfft(V * U_alt, n=n, dim=1)[:, :sl]\n",
    "\n",
    "    return U_plus, U_minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "D1OPt-Dex-P1"
   },
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def compute_spectral(\n",
    "    inputs: torch.Tensor,\n",
    "    eigh: tuple[torch.Tensor, torch.Tensor],\n",
    "    M_phi_plus: torch.Tensor,\n",
    "    M_phi_minus: torch.Tensor,\n",
    "    M_y: torch.Tensor = None,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the spectral component of the STU or AR-STU model, as described\n",
    "    in Equations (4) and (6) of the paper.\n",
    "\n",
    "    This function projects the input tensor into the spectral basis via\n",
    "    convolution and applies the precomputed spectral filters.\n",
    "\n",
    "    Args:\n",
    "        inputs (torch.Tensor): A tensor of shape [bsz, sl, d_in].\n",
    "        eigh (tuple[torch.Tensor, torch.Tensor]): Eigenvalues [K,] and eigenvectors [sl, K].\n",
    "        M_phi_plus (torch.Tensor): Positive spectral filter weights [d_out, K, d_in].\n",
    "        M_phi_minus (torch.Tensor): Negative spectral filter weights [d_out, K, d_in].\n",
    "        M_y (torch.Tensor, optional): Autoregressive weights for AR-STU [d_out, k_y, d_out].\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The spectral component tensor of shape [bsz, sl, d_out].\n",
    "    \"\"\"\n",
    "    sigma, phi = eigh\n",
    "    _, K = phi.shape\n",
    "\n",
    "    # Compute U⁺ and U⁻\n",
    "    U_plus, U_minus = conv(inputs, phi)  # -> tuple of [bsz, sl, K, d_in]\n",
    "\n",
    "    # Shift U⁺ and U⁻ k_y time steps\n",
    "    if M_y is not None:\n",
    "        k_y = M_y.shape[1]\n",
    "        U_plus, U_minus = shift(U_plus, k_y), shift(U_minus, k_y)\n",
    "\n",
    "    # Perform spectral filter on U⁺ and U⁻ w/ sigma\n",
    "    sigma_root = (sigma**0.25).view(1, 1, K, 1)\n",
    "    U_plus_filtered, U_minus_filtered = U_plus * sigma_root, U_minus * sigma_root\n",
    "\n",
    "    # Sum M^{\\phi +}_k \\cdot U_plus_filtered across K filters\n",
    "    spectral_plus = torch.einsum(\"bsKd,dKo->bso\", U_plus_filtered, M_phi_plus)\n",
    "\n",
    "    # Sum M^{\\phi -}_k \\cdot U_minus_filtered across K filters\n",
    "    spectral_minus = torch.einsum(\"bsKd,dKo->bso\", U_minus_filtered, M_phi_minus)\n",
    "\n",
    "    return spectral_plus + spectral_minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "H7w9I0sKyZVf"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SSSMConfigs:\n",
    "    d_in: int = 24\n",
    "    d_out: int = 18\n",
    "    n_layers: int = 6\n",
    "    n_embd: int = 512\n",
    "    sl: int = 300\n",
    "    scale: int = 4\n",
    "    bias: bool = False\n",
    "    dropout: float = 0.10\n",
    "    num_eigh: int = 24\n",
    "    k_u: int = 3  # Number of parametrizable, autoregressive matrices Mᵘ\n",
    "    k_y: int = 2  # Number of parametrizable, autoregressive matrices Mʸ\n",
    "    learnable_m_y: bool = True\n",
    "    alpha: float = 0.9  # 0.9 deemed \"uniformly optimal\" in the paper\n",
    "    use_hankel_L: bool = False\n",
    "    loss_fn: nn.Module = nn.MSELoss()\n",
    "    controls: dict = field(\n",
    "        default_factory=lambda: {\"task\": \"mujoco-v3\", \"controller\": \"Ant-v1\"}\n",
    "    )\n",
    "\n",
    "\n",
    "class STU(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple STU (Spectral Transform Unit) layer.\n",
    "\n",
    "    Args:\n",
    "        configs: Configuration object containing the following attributes:\n",
    "            d_in (int): Input dimension.\n",
    "            d_out (int): Output dimension.\n",
    "            sl (int): Input sequence length.\n",
    "            num_eigh (int): Number of spectral filters to use.\n",
    "            k_u (int): Autoregressive depth on the input sequence.\n",
    "            k_y (int): Autoregressive depth on the output sequence.\n",
    "            use_hankel_L (bool): Use the alternative Hankel matrix?\n",
    "            learnable_m_y (bool): Learn the M_y matrix?\n",
    "            dropout (float): Dropout rate.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs) -> None:\n",
    "        super(STU, self).__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.d_in = configs.n_embd\n",
    "        self.d_out = configs.n_embd\n",
    "        self.l, self.k = configs.sl, configs.num_eigh\n",
    "        self.use_hankel_L = configs.use_hankel_L\n",
    "        self.eigh = get_top_eigh(self.l, self.k, self.use_hankel_L, self.device)\n",
    "        self.k_u = configs.k_u\n",
    "        self.k_y = configs.k_y\n",
    "        self.learnable_m_y = configs.learnable_m_y\n",
    "        self.dropout = nn.Dropout(configs.dropout)\n",
    "\n",
    "        # Parameterizable matrix Mᵘ, Mᵠ⁺, and Mᵠ⁻, per section 3\n",
    "        self.M_u = nn.Parameter(torch.empty(self.d_out, self.k_u, self.d_in))\n",
    "        self.M_phi_plus = nn.Parameter(torch.empty(self.d_out, self.k, self.d_in))\n",
    "        self.M_phi_minus = nn.Parameter(torch.empty(self.d_out, self.k, self.d_in))\n",
    "\n",
    "        # Parametrizable matrix Mʸ Introduced in section 5, equation 5\n",
    "        if self.learnable_m_y:\n",
    "            self.M_y = nn.Parameter(torch.zeros(self.d_out, self.k_y, self.d_out))\n",
    "        else:\n",
    "            self.register_buffer(\"M_y\", torch.zeros(self.d_out, self.k_y, self.d_out))\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the STU layer.\n",
    "\n",
    "        Args:\n",
    "            inputs (torch.Tensor): Input tensor of shape (bsz, sl, d_in)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (bsz, sl, d_out)\n",
    "        \"\"\"\n",
    "        y_t = compute_spectral(inputs, self.eigh, self.M_phi_plus, self.M_phi_minus, self.M_y)\n",
    "\n",
    "        if self.k_u > 0:\n",
    "          if self.k_y > 0:\n",
    "            y_t += compute_ar(self.M_y, self.M_u, inputs)\n",
    "          else:\n",
    "            y_t += compute_ar_u(self.M_u, inputs)\n",
    "\n",
    "        return self.dropout(y_t)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple multi-layer perceptron network using SwiGLU activation.\n",
    "\n",
    "    Args:\n",
    "        configs: Configuration object containing the following attributes:\n",
    "            scale (float): Scaling factor for hidden dimension.\n",
    "            n_embd (int): Embedding dimension.\n",
    "            bias (bool): Whether to use bias in linear layers.\n",
    "            dropout (float): Dropout rate.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs: SSSMConfigs) -> None:\n",
    "        super(MLP, self).__init__()\n",
    "        self.h_dim = configs.scale * configs.n_embd\n",
    "        self.swiglu = SwiGLU(dim=configs.n_embd, h_dim=self.h_dim, bias=configs.bias)\n",
    "        self.dropout = nn.Dropout(configs.dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the MLP.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor\n",
    "        \"\"\"\n",
    "        x = self.swiglu(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    A single block of the SSSM model, consisting of STU and MLP layers.\n",
    "\n",
    "    Args:\n",
    "        configs: Configuration object for STU and MLP layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs: SSSMConfigs) -> None:\n",
    "        super(Block, self).__init__()\n",
    "        # Good configuration\n",
    "        self.rn_1 = nn.RMSNorm(configs.n_embd)\n",
    "        self.stu = STU(configs)\n",
    "        self.rn_2 = nn.RMSNorm(configs.n_embd)\n",
    "        self.mlp = MLP(configs)\n",
    "\n",
    "        # Basic configuration\n",
    "        # self.stu = STU(configs) #this also has a size problem [d_in,d_out] instead of [d_emb,  d_emb]\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the Block.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor\n",
    "        \"\"\"\n",
    "        # Good configuration\n",
    "        x = x + self.stu(self.rn_1(x))\n",
    "        x = x + self.mlp(self.rn_2(x))\n",
    "\n",
    "        # Basic configuration (no skips, no non-linearities)\n",
    "        # x = self.stu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SSSM(nn.Module):\n",
    "    \"\"\"\n",
    "    General model architecture based on stacked STU blocks and MLP layers.\n",
    "\n",
    "    Args:\n",
    "        configs: Configuration object containing model parameters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configs: SSSMConfigs) -> None:\n",
    "        super(SSSM, self).__init__()\n",
    "        self.configs = configs\n",
    "        self.n_layers = configs.n_layers\n",
    "        self.n_embd = configs.n_embd\n",
    "        self.d_in = configs.d_in\n",
    "        self.d_out = configs.d_out\n",
    "        self.sl = configs.sl\n",
    "        self.learnable_m_y = configs.learnable_m_y\n",
    "        self.alpha = configs.alpha\n",
    "\n",
    "        self.bias = configs.bias\n",
    "        self.dropout = configs.dropout\n",
    "        self.loss_fn = configs.loss_fn\n",
    "        self.controls = configs.controls\n",
    "\n",
    "        self.emb = nn.Linear(self.d_in, self.n_embd, bias=self.bias)\n",
    "        self.stu = nn.ModuleDict(\n",
    "            dict(\n",
    "                dropout=nn.Dropout(self.dropout),\n",
    "                hidden=nn.ModuleList([Block(configs) for _ in range(self.n_layers)]),\n",
    "            )\n",
    "        )\n",
    "        self.task_head = nn.Linear(self.n_embd, self.d_out, bias=self.bias)\n",
    "\n",
    "        # Initialize all weights\n",
    "        self.m_x = self.d_out**-0.5\n",
    "        self.std = self.n_embd**-0.5\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "        # Report the number of parameters\n",
    "        print(\"STU Model Parameter Count: %.2fM\" % (self.get_num_params() / 1e6,))\n",
    "\n",
    "    def forward(self, inputs, targets = None):\n",
    "        \"\"\"\n",
    "        Forward pass of the SSSM model.\n",
    "\n",
    "        Args:\n",
    "            inputs (torch.Tensor): Input tensor of shape (bsz, sl, d_in)\n",
    "            targets (torch.Tensor): Target tensor for loss computation\n",
    "\n",
    "        Returns:\n",
    "            Type (ignore due to high variability):\n",
    "            - Predictions tensor\n",
    "            - Tuple containing loss and metrics (if applicable)\n",
    "        \"\"\"\n",
    "        # _, sl, n_embd = inputs.size()\n",
    "\n",
    "        x = self.emb(inputs)\n",
    "        x = self.stu.dropout(x)\n",
    "\n",
    "        for block in self.stu.hidden:\n",
    "            x = block(x)\n",
    "\n",
    "        preds = self.task_head(x)\n",
    "\n",
    "        loss = self.loss_fn(preds, targets) if targets is not None else None\n",
    "        return ((preds, loss) if loss is not None else preds)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"\n",
    "        Initialize the weights of the model.\n",
    "\n",
    "        Args:\n",
    "            module (nn.Module): The module to initialize.\n",
    "        \"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            self.std *= (2 * self.n_layers) ** -0.5\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=self.std)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=self.std)\n",
    "        elif isinstance(module, STU):\n",
    "            torch.nn.init.uniform_(module.M_u, -self.m_x, self.m_x)\n",
    "            torch.nn.init.zeros_(module.M_phi_plus)\n",
    "            torch.nn.init.zeros_(module.M_phi_minus)\n",
    "\n",
    "    def get_num_params(self, non_embedding=True):\n",
    "        \"\"\"\n",
    "        Return the number of parameters in the model.\n",
    "\n",
    "        Args:\n",
    "            non_embedding (bool, optional):\n",
    "            Whether to exclude the positional embeddings (if applicable).\n",
    "            Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            int: The number of parameters in the model.\n",
    "        \"\"\"\n",
    "        num_params = sum(p.numel() for p in self.parameters())\n",
    "        return num_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8RJEm4Z0hQ_",
    "outputId": "cd7bcf1b-1cb4-4e81-ac4e-7e36bdd095ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STU Model Parameter Count: 0.01M\n"
     ]
    }
   ],
   "source": [
    "bsz=1 # @param\n",
    "n_layers=2 # @param\n",
    "n_embd=8 # @param\n",
    "d_in=24 # @param\n",
    "d_out=18 # @param\n",
    "sl=512 # @param\n",
    "scale=4 # @param\n",
    "bias=False # @param\n",
    "dropout=0.0 # @param\n",
    "num_eigh=16 # @param\n",
    "k_u=3 # @param\n",
    "k_y=0 # @param\n",
    "learnable_m_y=True # @param\n",
    "alpha=0.9 # @param\n",
    "use_hankel_L=False # @param\n",
    "loss_fn=nn.MSELoss() # @param\n",
    "lr=1e-1 # @param\n",
    "delta=0.01 # @param\n",
    "\n",
    "configs = SSSMConfigs(\n",
    "  n_layers=n_layers,\n",
    "  n_embd=n_embd,\n",
    "  d_in=d_in,\n",
    "  d_out=d_out,\n",
    "  sl=sl,\n",
    "  scale=scale,\n",
    "  bias=bias,\n",
    "  dropout=dropout,\n",
    "  num_eigh=num_eigh,\n",
    "  k_u=k_u,\n",
    "  k_y=k_y,\n",
    "  learnable_m_y=learnable_m_y,\n",
    "  alpha=alpha,\n",
    "  use_hankel_L=use_hankel_L,\n",
    "  loss_fn=loss_fn,\n",
    ")\n",
    "\n",
    "model = SSSM(configs).to(device)\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\n",
      "Creating dataloader on cuda for task: mujoco-v1\u001b[0m\n",
      "Using sequence length: 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Apply Gaussian noise to data?: Disabled\n",
      "\u001b[94m\n",
      "Calculating data statistics...\u001b[0m\n",
      "\u001b[94mNormalizing data...\u001b[0m\n",
      "\u001b[94mValidating data normalization...\u001b[0m\n",
      "\u001b[92m\n",
      "Normalized mean of inputs for coordinates: [0.00018377 0.0004239 ]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of inputs for coordinates: [0.99988493 1.00014359]\u001b[0m\n",
      "\u001b[92mNormalized mean of targets for coordinates: [-0.00018377 -0.0004239 ]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of targets for coordinates: [1.00011158 0.99980374]\u001b[0m\n",
      "\u001b[92m\n",
      "Normalized mean of inputs for angles: [-0.00020589 -0.00096165 -0.00018324  0.00073418 -0.00010059 -0.00011929\n",
      " -0.00011729]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of inputs for angles: [1.00041433 1.00185566 1.00013121 1.00021316 1.00018604 1.00035338\n",
      " 1.00017155]\u001b[0m\n",
      "\u001b[92mNormalized mean of targets for angles: [ 0.00020589  0.00096165  0.00018324 -0.00073418  0.00010059  0.00011929\n",
      "  0.00011729]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of targets for angles: [0.99954492 0.9977162  0.9997683  0.9997608  0.99939967 0.99954043\n",
      " 0.9998055 ]\u001b[0m\n",
      "\u001b[92m\n",
      "Normalized mean of inputs for coordinate_velocities: [ 0.00023379 -0.00012828]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of inputs for coordinate_velocities: [1.00050389 1.00003277]\u001b[0m\n",
      "\u001b[92mNormalized mean of targets for coordinate_velocities: [-0.00023379  0.00012828]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of targets for coordinate_velocities: [0.99948129 0.99995449]\u001b[0m\n",
      "\u001b[92m\n",
      "Normalized mean of inputs for angular_velocities: [ 3.28207562e-05  2.49162060e-05 -1.21271749e-05 -3.17272072e-04\n",
      "  1.78593172e-05 -5.56011537e-06  2.38656492e-04]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of inputs for angular_velocities: [1.00014932 1.00054625 1.00016789 1.00032316 0.99962519 1.00011136\n",
      " 0.99996271]\u001b[0m\n",
      "\u001b[92mNormalized mean of targets for angular_velocities: [-3.28207562e-05 -2.49162060e-05  1.21271749e-05  3.17272072e-04\n",
      " -1.78593172e-05  5.56011537e-06 -2.38656492e-04]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of targets for angular_velocities: [0.99984485 0.99944538 0.99982847 0.99967394 1.00036605 0.99988489\n",
      " 1.00003486]\u001b[0m\n",
      "\u001b[92m\n",
      "Normalized mean of inputs for torque: [-4.62952337e-17 -4.98681692e-17 -5.88959294e-18 -6.86438376e-16\n",
      " -8.99262482e-17  5.87139334e-17]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of inputs for torque: [0.99997337 0.99997864 0.99998755 0.99977441 0.99997176 0.99998938]\u001b[0m\n",
      "\u001b[1m\u001b[92mData normalization validated successfully.\u001b[0m\n",
      "\u001b[92mDataloader created successfully.\u001b[0m\n",
      "\u001b[94m\n",
      "Creating dataloader on cuda for task: mujoco-v1\u001b[0m\n",
      "Using sequence length: 512\n",
      "\n",
      "Apply Gaussian noise to data?: Disabled\n",
      "\u001b[94m\n",
      "Calculating data statistics...\u001b[0m\n",
      "\u001b[94mNormalizing data...\u001b[0m\n",
      "\u001b[94mValidating data normalization...\u001b[0m\n",
      "\u001b[92m\n",
      "Normalized mean of inputs for coordinates: [-0.00073541 -0.00169415]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of inputs for coordinates: [1.00045294 0.99929953]\u001b[0m\n",
      "\u001b[92mNormalized mean of targets for coordinates: [0.00073541 0.00169415]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of targets for coordinates: [0.99954287 1.00064472]\u001b[0m\n",
      "\u001b[92m\n",
      "Normalized mean of inputs for angles: [ 0.00082333  0.00383343  0.00073323 -0.00293492  0.00040419  0.00047672\n",
      "  0.00046875]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of inputs for angles: [0.99824278 0.99149925 0.99922457 0.99908021 0.99821533 0.99831713\n",
      " 0.99925645]\u001b[0m\n",
      "\u001b[92mNormalized mean of targets for angles: [-0.00082333 -0.00383343 -0.00073323  0.00293492 -0.00040419 -0.00047672\n",
      " -0.00046875]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of targets for angles: [1.00171304 1.0079956  1.00067394 1.00088491 1.00136749 1.00157388\n",
      " 1.00071988]\u001b[0m\n",
      "\u001b[92m\n",
      "Normalized mean of inputs for coordinate_velocities: [-0.0009364   0.00051173]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of inputs for coordinate_velocities: [0.99793967 0.99983744]\u001b[0m\n",
      "\u001b[92mNormalized mean of targets for coordinate_velocities: [ 0.0009364  -0.00051173]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of targets for coordinate_velocities: [1.00204072 1.00014959]\u001b[0m\n",
      "\u001b[92m\n",
      "Normalized mean of inputs for angular_velocities: [-1.31102936e-04 -9.94288561e-05  4.84091778e-05  1.26707851e-03\n",
      " -7.12301366e-05  2.21757815e-05 -9.53706499e-04]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of inputs for angular_velocities: [0.99938935 0.99780371 0.99932105 0.99870094 1.00146769 0.99954576\n",
      " 1.00014297]\u001b[0m\n",
      "\u001b[92mNormalized mean of targets for angular_velocities: [ 1.31102936e-04  9.94288561e-05 -4.84091778e-05 -1.26707851e-03\n",
      "  7.12301366e-05 -2.21757815e-05  9.53706499e-04]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of targets for angular_velocities: [1.00060446 1.00218343 1.00067489 1.00129309 0.99852153 1.00045031\n",
      " 0.99985372]\u001b[0m\n",
      "\u001b[92m\n",
      "Normalized mean of inputs for torque: [ 4.51998167e-17  1.74249741e-17 -2.87451428e-17 -6.49171249e-16\n",
      " -6.95988233e-17  3.67905485e-17]\u001b[0m\n",
      "\u001b[92mNormalized standard deviation of inputs for torque: [0.99997357 0.99997865 0.99998755 0.99977556 0.99997179 0.99998939]\u001b[0m\n",
      "\u001b[1m\u001b[92mData normalization validated successfully.\u001b[0m\n",
      "\u001b[92mDataloader created successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "controller = 'Walker2D-v1' #@param\n",
    "train_data = {\n",
    "    \"inputs\": f\"data/mujoco-v1/{controller}/train_inputs.npy\",\n",
    "    \"targets\": f\"data/mujoco-v1/{controller}/train_targets.npy\",\n",
    "}\n",
    "val_data = {\n",
    "    \"inputs\": f\"data/mujoco-v1/{controller}/val_inputs.npy\",\n",
    "    \"targets\": f\"data/mujoco-v1/{controller}/val_targets.npy\",\n",
    "}\n",
    "\n",
    "from utils.dataloader import get_dataloader \n",
    "\n",
    "train_loader = get_dataloader(\n",
    "    model  = 'spectral_ssm',\n",
    "    data = train_data,\n",
    "    task = 'mujoco-v1',\n",
    "    controller = controller,\n",
    "    bsz  = bsz,\n",
    "    preprocess =  True, #normalize\n",
    "    shuffle= True,\n",
    "    sl = sl,\n",
    "    device = device\n",
    ")\n",
    "\n",
    "val_loader = get_dataloader(\n",
    "    model  = 'spectral_ssm',\n",
    "    data = val_data,\n",
    "    task = 'mujoco-v1',\n",
    "    controller =  controller,\n",
    "    bsz = bsz,\n",
    "    preprocess =  True, #normalize\n",
    "    shuffle= True,\n",
    "    sl = sl,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using batch size: 1\n",
      "Number of epochs: 1\n",
      "Steps per epoch: 2811\n",
      "=> Number of training steps: 2811\n"
     ]
    }
   ],
   "source": [
    "training_stu = True #@param\n",
    "num_epochs: int = 1 #@param\n",
    "steps_per_epoch = len(train_loader) #@param\n",
    "num_steps: int = steps_per_epoch * num_epochs #@param\n",
    "dilation: int = 1 #@param\n",
    "warmup_steps: int = num_steps // 8 #@param\n",
    "eval_period: int = num_steps // 16 #@param\n",
    "\n",
    "print(f\"\\nUsing batch size: {bsz}\")\n",
    "print(f\"Number of epochs: {num_epochs}\")\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"=> Number of training steps: {num_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from utils.colors import Colors, colored_print\n",
    "from losses.loss_ant import AntLoss\n",
    "from losses.loss_cheetah import HalfCheetahLoss\n",
    "from losses.loss_walker import Walker2DLoss\n",
    "from losses.loss_cartpole import CartpoleLoss\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "checkpoint_dir: str = \"checkpoints\"\n",
    "if controller == \"Ant-v1\":\n",
    "    loss_fn = AntLoss()\n",
    "elif controller == \"HalfCheetah-v1\":\n",
    "    loss_fn = HalfCheetahLoss()\n",
    "elif controller == \"Walker2D-v1\":\n",
    "    loss_fn = Walker2DLoss()\n",
    "elif controller == \"CartPole-v1\":\n",
    "    loss_fn = CartpoleLoss()\n",
    "else:\n",
    "    loss_fn = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_counter = 0\n",
    "best_val_loss = float(\"inf\")\n",
    "best_model_step = 0\n",
    "best_checkpoint = None\n",
    "patience: int = 10 #number of  non-improving eval periods before early stoppig\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_time_steps = []\n",
    "grad_norms = []\n",
    "\n",
    "model  = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 0.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 1.9683.\u001b[0m\n",
      "\u001b[92mNew best validation loss: 1.9683. Model checkpoint saved at checkpoints\\sssm-Walker2D-v1-model_step-0-2024-11-18-22-01-56.pt.\u001b[0m\n",
      "\u001b[95m\n",
      "Step     0\u001b[0m\n",
      "\u001b[94mLoss: 1.971432 | Gradient Norm: 0.6307\u001b[0m\n",
      "\u001b[95m\n",
      "Step    10\u001b[0m\n",
      "\u001b[94mLoss: 1.039928 | Gradient Norm: 0.5656\u001b[0m\n",
      "\u001b[95m\n",
      "Step    20\u001b[0m\n",
      "\u001b[94mLoss: 0.819690 | Gradient Norm: 0.3232\u001b[0m\n",
      "\u001b[95m\n",
      "Step    30\u001b[0m\n",
      "\u001b[94mLoss: 1.256488 | Gradient Norm: 0.4011\u001b[0m\n",
      "\u001b[95m\n",
      "Step    40\u001b[0m\n",
      "\u001b[94mLoss: 0.801146 | Gradient Norm: 0.2998\u001b[0m\n",
      "\u001b[95m\n",
      "Step    50\u001b[0m\n",
      "\u001b[94mLoss: 0.758886 | Gradient Norm: 0.1969\u001b[0m\n",
      "\u001b[95m\n",
      "Step    60\u001b[0m\n",
      "\u001b[94mLoss: 0.851063 | Gradient Norm: 0.2753\u001b[0m\n",
      "\u001b[95m\n",
      "Step    70\u001b[0m\n",
      "\u001b[94mLoss: 0.748405 | Gradient Norm: 0.1743\u001b[0m\n",
      "\u001b[95m\n",
      "Step    80\u001b[0m\n",
      "\u001b[94mLoss: 0.895121 | Gradient Norm: 0.2710\u001b[0m\n",
      "\u001b[95m\n",
      "Step    90\u001b[0m\n",
      "\u001b[94mLoss: 0.830962 | Gradient Norm: 0.5261\u001b[0m\n",
      "\u001b[95m\n",
      "Step   100\u001b[0m\n",
      "\u001b[94mLoss: 1.261117 | Gradient Norm: 0.3106\u001b[0m\n",
      "\u001b[95m\n",
      "Step   110\u001b[0m\n",
      "\u001b[94mLoss: 0.870344 | Gradient Norm: 0.3866\u001b[0m\n",
      "\u001b[95m\n",
      "Step   120\u001b[0m\n",
      "\u001b[94mLoss: 0.833179 | Gradient Norm: 0.2418\u001b[0m\n",
      "\u001b[95m\n",
      "Step   130\u001b[0m\n",
      "\u001b[94mLoss: 0.778811 | Gradient Norm: 0.1900\u001b[0m\n",
      "\u001b[95m\n",
      "Step   140\u001b[0m\n",
      "\u001b[94mLoss: 0.713457 | Gradient Norm: 0.1561\u001b[0m\n",
      "\u001b[95m\n",
      "Step   150\u001b[0m\n",
      "\u001b[94mLoss: 0.779014 | Gradient Norm: 0.2204\u001b[0m\n",
      "\u001b[95m\n",
      "Step   160\u001b[0m\n",
      "\u001b[94mLoss: 0.749896 | Gradient Norm: 0.2369\u001b[0m\n",
      "\u001b[95m\n",
      "Step   170\u001b[0m\n",
      "\u001b[94mLoss: 0.849785 | Gradient Norm: 0.2848\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 175.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8700.\u001b[0m\n",
      "\u001b[92mNew best validation loss: 0.8700. Model checkpoint saved at checkpoints\\sssm-Walker2D-v1-model_step-175-2024-11-18-22-01-56.pt.\u001b[0m\n",
      "\u001b[95m\n",
      "Step   180\u001b[0m\n",
      "\u001b[94mLoss: 0.770905 | Gradient Norm: 0.1775\u001b[0m\n",
      "\u001b[95m\n",
      "Step   190\u001b[0m\n",
      "\u001b[94mLoss: 1.248054 | Gradient Norm: 0.2907\u001b[0m\n",
      "\u001b[95m\n",
      "Step   200\u001b[0m\n",
      "\u001b[94mLoss: 0.807797 | Gradient Norm: 0.1729\u001b[0m\n",
      "\u001b[95m\n",
      "Step   210\u001b[0m\n",
      "\u001b[94mLoss: 0.707271 | Gradient Norm: 0.1582\u001b[0m\n",
      "\u001b[95m\n",
      "Step   220\u001b[0m\n",
      "\u001b[94mLoss: 0.957021 | Gradient Norm: 0.3009\u001b[0m\n",
      "\u001b[95m\n",
      "Step   230\u001b[0m\n",
      "\u001b[94mLoss: 0.821289 | Gradient Norm: 0.2584\u001b[0m\n",
      "\u001b[95m\n",
      "Step   240\u001b[0m\n",
      "\u001b[94mLoss: 0.814751 | Gradient Norm: 0.2388\u001b[0m\n",
      "\u001b[95m\n",
      "Step   250\u001b[0m\n",
      "\u001b[94mLoss: 1.486725 | Gradient Norm: 0.4743\u001b[0m\n",
      "\u001b[95m\n",
      "Step   260\u001b[0m\n",
      "\u001b[94mLoss: 0.886244 | Gradient Norm: 0.1782\u001b[0m\n",
      "\u001b[95m\n",
      "Step   270\u001b[0m\n",
      "\u001b[94mLoss: 1.087457 | Gradient Norm: 0.2466\u001b[0m\n",
      "\u001b[95m\n",
      "Step   280\u001b[0m\n",
      "\u001b[94mLoss: 0.778180 | Gradient Norm: 0.1654\u001b[0m\n",
      "\u001b[95m\n",
      "Step   290\u001b[0m\n",
      "\u001b[94mLoss: 0.761257 | Gradient Norm: 0.2136\u001b[0m\n",
      "\u001b[95m\n",
      "Step   300\u001b[0m\n",
      "\u001b[94mLoss: 0.862364 | Gradient Norm: 0.2644\u001b[0m\n",
      "\u001b[95m\n",
      "Step   310\u001b[0m\n",
      "\u001b[94mLoss: 2.298979 | Gradient Norm: 0.3754\u001b[0m\n",
      "\u001b[95m\n",
      "Step   320\u001b[0m\n",
      "\u001b[94mLoss: 0.846479 | Gradient Norm: 0.1485\u001b[0m\n",
      "\u001b[95m\n",
      "Step   330\u001b[0m\n",
      "\u001b[94mLoss: 0.773747 | Gradient Norm: 0.3536\u001b[0m\n",
      "\u001b[95m\n",
      "Step   340\u001b[0m\n",
      "\u001b[94mLoss: 0.892880 | Gradient Norm: 0.1836\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 350.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8677.\u001b[0m\n",
      "\u001b[92mNew best validation loss: 0.8677. Model checkpoint saved at checkpoints\\sssm-Walker2D-v1-model_step-350-2024-11-18-22-01-56.pt.\u001b[0m\n",
      "\u001b[95m\n",
      "Step   350\u001b[0m\n",
      "\u001b[94mLoss: 0.670310 | Gradient Norm: 0.2256\u001b[0m\n",
      "\u001b[95m\n",
      "Step   360\u001b[0m\n",
      "\u001b[94mLoss: 0.698878 | Gradient Norm: 0.2340\u001b[0m\n",
      "\u001b[95m\n",
      "Step   370\u001b[0m\n",
      "\u001b[94mLoss: 0.958036 | Gradient Norm: 0.2571\u001b[0m\n",
      "\u001b[95m\n",
      "Step   380\u001b[0m\n",
      "\u001b[94mLoss: 1.283095 | Gradient Norm: 0.3183\u001b[0m\n",
      "\u001b[95m\n",
      "Step   390\u001b[0m\n",
      "\u001b[94mLoss: 0.952013 | Gradient Norm: 0.1754\u001b[0m\n",
      "\u001b[95m\n",
      "Step   400\u001b[0m\n",
      "\u001b[94mLoss: 0.877295 | Gradient Norm: 0.1714\u001b[0m\n",
      "\u001b[95m\n",
      "Step   410\u001b[0m\n",
      "\u001b[94mLoss: 0.886054 | Gradient Norm: 0.1512\u001b[0m\n",
      "\u001b[95m\n",
      "Step   420\u001b[0m\n",
      "\u001b[94mLoss: 0.895116 | Gradient Norm: 0.1871\u001b[0m\n",
      "\u001b[95m\n",
      "Step   430\u001b[0m\n",
      "\u001b[94mLoss: 0.842533 | Gradient Norm: 0.1160\u001b[0m\n",
      "\u001b[95m\n",
      "Step   440\u001b[0m\n",
      "\u001b[94mLoss: 0.828019 | Gradient Norm: 0.1353\u001b[0m\n",
      "\u001b[95m\n",
      "Step   450\u001b[0m\n",
      "\u001b[94mLoss: 0.756766 | Gradient Norm: 0.2568\u001b[0m\n",
      "\u001b[95m\n",
      "Step   460\u001b[0m\n",
      "\u001b[94mLoss: 0.888007 | Gradient Norm: 0.2242\u001b[0m\n",
      "\u001b[95m\n",
      "Step   470\u001b[0m\n",
      "\u001b[94mLoss: 0.817798 | Gradient Norm: 0.1969\u001b[0m\n",
      "\u001b[95m\n",
      "Step   480\u001b[0m\n",
      "\u001b[94mLoss: 0.900760 | Gradient Norm: 0.3235\u001b[0m\n",
      "\u001b[95m\n",
      "Step   490\u001b[0m\n",
      "\u001b[94mLoss: 0.851752 | Gradient Norm: 0.1713\u001b[0m\n",
      "\u001b[95m\n",
      "Step   500\u001b[0m\n",
      "\u001b[94mLoss: 0.919647 | Gradient Norm: 0.1859\u001b[0m\n",
      "\u001b[95m\n",
      "Step   510\u001b[0m\n",
      "\u001b[94mLoss: 0.835312 | Gradient Norm: 0.2459\u001b[0m\n",
      "\u001b[95m\n",
      "Step   520\u001b[0m\n",
      "\u001b[94mLoss: 0.827410 | Gradient Norm: 0.1707\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 525.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8661.\u001b[0m\n",
      "\u001b[92mNew best validation loss: 0.8661. Model checkpoint saved at checkpoints\\sssm-Walker2D-v1-model_step-525-2024-11-18-22-01-56.pt.\u001b[0m\n",
      "\u001b[95m\n",
      "Step   530\u001b[0m\n",
      "\u001b[94mLoss: 0.848008 | Gradient Norm: 0.3171\u001b[0m\n",
      "\u001b[95m\n",
      "Step   540\u001b[0m\n",
      "\u001b[94mLoss: 1.078777 | Gradient Norm: 0.2513\u001b[0m\n",
      "\u001b[95m\n",
      "Step   550\u001b[0m\n",
      "\u001b[94mLoss: 0.706150 | Gradient Norm: 0.1699\u001b[0m\n",
      "\u001b[95m\n",
      "Step   560\u001b[0m\n",
      "\u001b[94mLoss: 0.828427 | Gradient Norm: 0.2285\u001b[0m\n",
      "\u001b[95m\n",
      "Step   570\u001b[0m\n",
      "\u001b[94mLoss: 0.878075 | Gradient Norm: 0.1316\u001b[0m\n",
      "\u001b[95m\n",
      "Step   580\u001b[0m\n",
      "\u001b[94mLoss: 0.761963 | Gradient Norm: 0.2147\u001b[0m\n",
      "\u001b[95m\n",
      "Step   590\u001b[0m\n",
      "\u001b[94mLoss: 0.670998 | Gradient Norm: 0.1237\u001b[0m\n",
      "\u001b[95m\n",
      "Step   600\u001b[0m\n",
      "\u001b[94mLoss: 0.893938 | Gradient Norm: 0.3923\u001b[0m\n",
      "\u001b[95m\n",
      "Step   610\u001b[0m\n",
      "\u001b[94mLoss: 0.841345 | Gradient Norm: 0.1507\u001b[0m\n",
      "\u001b[95m\n",
      "Step   620\u001b[0m\n",
      "\u001b[94mLoss: 0.870120 | Gradient Norm: 0.3545\u001b[0m\n",
      "\u001b[95m\n",
      "Step   630\u001b[0m\n",
      "\u001b[94mLoss: 0.861607 | Gradient Norm: 0.2028\u001b[0m\n",
      "\u001b[95m\n",
      "Step   640\u001b[0m\n",
      "\u001b[94mLoss: 0.811591 | Gradient Norm: 0.2239\u001b[0m\n",
      "\u001b[95m\n",
      "Step   650\u001b[0m\n",
      "\u001b[94mLoss: 1.034750 | Gradient Norm: 0.2598\u001b[0m\n",
      "\u001b[95m\n",
      "Step   660\u001b[0m\n",
      "\u001b[94mLoss: 1.229245 | Gradient Norm: 0.3032\u001b[0m\n",
      "\u001b[95m\n",
      "Step   670\u001b[0m\n",
      "\u001b[94mLoss: 1.137807 | Gradient Norm: 0.2837\u001b[0m\n",
      "\u001b[95m\n",
      "Step   680\u001b[0m\n",
      "\u001b[94mLoss: 0.659953 | Gradient Norm: 0.1178\u001b[0m\n",
      "\u001b[95m\n",
      "Step   690\u001b[0m\n",
      "\u001b[94mLoss: 0.737290 | Gradient Norm: 0.1070\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 700.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8643.\u001b[0m\n",
      "\u001b[92mNew best validation loss: 0.8643. Model checkpoint saved at checkpoints\\sssm-Walker2D-v1-model_step-700-2024-11-18-22-01-56.pt.\u001b[0m\n",
      "\u001b[95m\n",
      "Step   700\u001b[0m\n",
      "\u001b[94mLoss: 0.883492 | Gradient Norm: 0.1396\u001b[0m\n",
      "\u001b[95m\n",
      "Step   710\u001b[0m\n",
      "\u001b[94mLoss: 0.783752 | Gradient Norm: 0.1488\u001b[0m\n",
      "\u001b[95m\n",
      "Step   720\u001b[0m\n",
      "\u001b[94mLoss: 0.875455 | Gradient Norm: 0.1959\u001b[0m\n",
      "\u001b[95m\n",
      "Step   730\u001b[0m\n",
      "\u001b[94mLoss: 0.943575 | Gradient Norm: 0.2472\u001b[0m\n",
      "\u001b[95m\n",
      "Step   740\u001b[0m\n",
      "\u001b[94mLoss: 0.921210 | Gradient Norm: 0.2131\u001b[0m\n",
      "\u001b[95m\n",
      "Step   750\u001b[0m\n",
      "\u001b[94mLoss: 0.803463 | Gradient Norm: 0.1614\u001b[0m\n",
      "\u001b[95m\n",
      "Step   760\u001b[0m\n",
      "\u001b[94mLoss: 0.985694 | Gradient Norm: 0.1561\u001b[0m\n",
      "\u001b[95m\n",
      "Step   770\u001b[0m\n",
      "\u001b[94mLoss: 0.688319 | Gradient Norm: 0.2071\u001b[0m\n",
      "\u001b[95m\n",
      "Step   780\u001b[0m\n",
      "\u001b[94mLoss: 0.827985 | Gradient Norm: 0.1312\u001b[0m\n",
      "\u001b[95m\n",
      "Step   790\u001b[0m\n",
      "\u001b[94mLoss: 0.801967 | Gradient Norm: 0.1369\u001b[0m\n",
      "\u001b[95m\n",
      "Step   800\u001b[0m\n",
      "\u001b[94mLoss: 0.847401 | Gradient Norm: 0.1658\u001b[0m\n",
      "\u001b[95m\n",
      "Step   810\u001b[0m\n",
      "\u001b[94mLoss: 1.226196 | Gradient Norm: 0.2404\u001b[0m\n",
      "\u001b[95m\n",
      "Step   820\u001b[0m\n",
      "\u001b[94mLoss: 0.935809 | Gradient Norm: 0.1574\u001b[0m\n",
      "\u001b[95m\n",
      "Step   830\u001b[0m\n",
      "\u001b[94mLoss: 0.834272 | Gradient Norm: 0.1611\u001b[0m\n",
      "\u001b[95m\n",
      "Step   840\u001b[0m\n",
      "\u001b[94mLoss: 0.843315 | Gradient Norm: 0.1524\u001b[0m\n",
      "\u001b[95m\n",
      "Step   850\u001b[0m\n",
      "\u001b[94mLoss: 0.804396 | Gradient Norm: 0.1853\u001b[0m\n",
      "\u001b[95m\n",
      "Step   860\u001b[0m\n",
      "\u001b[94mLoss: 0.784868 | Gradient Norm: 0.1209\u001b[0m\n",
      "\u001b[95m\n",
      "Step   870\u001b[0m\n",
      "\u001b[94mLoss: 0.752939 | Gradient Norm: 0.2517\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 875.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8670.\u001b[0m\n",
      "\u001b[93mNo improvement in validation loss. Current best: 0.8643.\u001b[0m\n",
      "\u001b[95m\n",
      "Step   880\u001b[0m\n",
      "\u001b[94mLoss: 0.721411 | Gradient Norm: 0.2230\u001b[0m\n",
      "\u001b[95m\n",
      "Step   890\u001b[0m\n",
      "\u001b[94mLoss: 0.802880 | Gradient Norm: 0.1657\u001b[0m\n",
      "\u001b[95m\n",
      "Step   900\u001b[0m\n",
      "\u001b[94mLoss: 0.830803 | Gradient Norm: 0.2275\u001b[0m\n",
      "\u001b[95m\n",
      "Step   910\u001b[0m\n",
      "\u001b[94mLoss: 0.824452 | Gradient Norm: 0.2103\u001b[0m\n",
      "\u001b[95m\n",
      "Step   920\u001b[0m\n",
      "\u001b[94mLoss: 0.932204 | Gradient Norm: 0.2063\u001b[0m\n",
      "\u001b[95m\n",
      "Step   930\u001b[0m\n",
      "\u001b[94mLoss: 0.810554 | Gradient Norm: 0.2110\u001b[0m\n",
      "\u001b[95m\n",
      "Step   940\u001b[0m\n",
      "\u001b[94mLoss: 1.525360 | Gradient Norm: 0.3350\u001b[0m\n",
      "\u001b[95m\n",
      "Step   950\u001b[0m\n",
      "\u001b[94mLoss: 0.910502 | Gradient Norm: 0.1637\u001b[0m\n",
      "\u001b[95m\n",
      "Step   960\u001b[0m\n",
      "\u001b[94mLoss: 0.779976 | Gradient Norm: 0.2825\u001b[0m\n",
      "\u001b[95m\n",
      "Step   970\u001b[0m\n",
      "\u001b[94mLoss: 0.767182 | Gradient Norm: 0.1378\u001b[0m\n",
      "\u001b[95m\n",
      "Step   980\u001b[0m\n",
      "\u001b[94mLoss: 0.831719 | Gradient Norm: 0.3687\u001b[0m\n",
      "\u001b[95m\n",
      "Step   990\u001b[0m\n",
      "\u001b[94mLoss: 0.755188 | Gradient Norm: 0.1661\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1000\u001b[0m\n",
      "\u001b[94mLoss: 0.740466 | Gradient Norm: 0.1400\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1010\u001b[0m\n",
      "\u001b[94mLoss: 0.652970 | Gradient Norm: 0.1617\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1020\u001b[0m\n",
      "\u001b[94mLoss: 0.991600 | Gradient Norm: 0.1892\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1030\u001b[0m\n",
      "\u001b[94mLoss: 0.970351 | Gradient Norm: 0.1911\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1040\u001b[0m\n",
      "\u001b[94mLoss: 0.997767 | Gradient Norm: 0.2079\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1050.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8601.\u001b[0m\n",
      "\u001b[92mNew best validation loss: 0.8601. Model checkpoint saved at checkpoints\\sssm-Walker2D-v1-model_step-1050-2024-11-18-22-01-56.pt.\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1050\u001b[0m\n",
      "\u001b[94mLoss: 0.701144 | Gradient Norm: 0.1618\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1060\u001b[0m\n",
      "\u001b[94mLoss: 0.904952 | Gradient Norm: 0.1151\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1070\u001b[0m\n",
      "\u001b[94mLoss: 0.803943 | Gradient Norm: 0.1468\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1080\u001b[0m\n",
      "\u001b[94mLoss: 0.789435 | Gradient Norm: 0.1660\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1090\u001b[0m\n",
      "\u001b[94mLoss: 0.795611 | Gradient Norm: 0.2244\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1100\u001b[0m\n",
      "\u001b[94mLoss: 0.952228 | Gradient Norm: 0.2688\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1110\u001b[0m\n",
      "\u001b[94mLoss: 0.820159 | Gradient Norm: 0.1111\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1120\u001b[0m\n",
      "\u001b[94mLoss: 0.820838 | Gradient Norm: 0.1234\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1130\u001b[0m\n",
      "\u001b[94mLoss: 1.089042 | Gradient Norm: 0.1948\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1140\u001b[0m\n",
      "\u001b[94mLoss: 0.983395 | Gradient Norm: 0.1546\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1150\u001b[0m\n",
      "\u001b[94mLoss: 0.828262 | Gradient Norm: 0.1370\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1160\u001b[0m\n",
      "\u001b[94mLoss: 0.870158 | Gradient Norm: 0.2529\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1170\u001b[0m\n",
      "\u001b[94mLoss: 1.071174 | Gradient Norm: 0.2895\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1180\u001b[0m\n",
      "\u001b[94mLoss: 0.864782 | Gradient Norm: 0.1560\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1190\u001b[0m\n",
      "\u001b[94mLoss: 0.925685 | Gradient Norm: 0.1696\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1200\u001b[0m\n",
      "\u001b[94mLoss: 0.814100 | Gradient Norm: 0.1575\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1210\u001b[0m\n",
      "\u001b[94mLoss: 0.783587 | Gradient Norm: 0.1536\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1220\u001b[0m\n",
      "\u001b[94mLoss: 0.935165 | Gradient Norm: 0.2144\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1225.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8608.\u001b[0m\n",
      "\u001b[93mNo improvement in validation loss. Current best: 0.8601.\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1230\u001b[0m\n",
      "\u001b[94mLoss: 0.557815 | Gradient Norm: 0.2834\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1240\u001b[0m\n",
      "\u001b[94mLoss: 0.750243 | Gradient Norm: 0.3195\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1250\u001b[0m\n",
      "\u001b[94mLoss: 0.921702 | Gradient Norm: 0.1798\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1260\u001b[0m\n",
      "\u001b[94mLoss: 0.774638 | Gradient Norm: 0.1408\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1270\u001b[0m\n",
      "\u001b[94mLoss: 0.728264 | Gradient Norm: 0.1301\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1280\u001b[0m\n",
      "\u001b[94mLoss: 0.868046 | Gradient Norm: 0.1664\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1290\u001b[0m\n",
      "\u001b[94mLoss: 0.962057 | Gradient Norm: 0.2411\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1300\u001b[0m\n",
      "\u001b[94mLoss: 0.778736 | Gradient Norm: 0.2310\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1310\u001b[0m\n",
      "\u001b[94mLoss: 0.850742 | Gradient Norm: 0.1318\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1320\u001b[0m\n",
      "\u001b[94mLoss: 0.801619 | Gradient Norm: 0.2024\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1330\u001b[0m\n",
      "\u001b[94mLoss: 1.038490 | Gradient Norm: 0.2950\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1340\u001b[0m\n",
      "\u001b[94mLoss: 0.716769 | Gradient Norm: 0.1359\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1350\u001b[0m\n",
      "\u001b[94mLoss: 1.042919 | Gradient Norm: 0.2065\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1360\u001b[0m\n",
      "\u001b[94mLoss: 0.726173 | Gradient Norm: 0.1646\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1370\u001b[0m\n",
      "\u001b[94mLoss: 0.672434 | Gradient Norm: 0.2500\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1380\u001b[0m\n",
      "\u001b[94mLoss: 0.853092 | Gradient Norm: 0.2342\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1390\u001b[0m\n",
      "\u001b[94mLoss: 0.845091 | Gradient Norm: 0.2248\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1400.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8593.\u001b[0m\n",
      "\u001b[92mNew best validation loss: 0.8593. Model checkpoint saved at checkpoints\\sssm-Walker2D-v1-model_step-1400-2024-11-18-22-01-56.pt.\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1400\u001b[0m\n",
      "\u001b[94mLoss: 0.871837 | Gradient Norm: 0.1780\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1410\u001b[0m\n",
      "\u001b[94mLoss: 0.905923 | Gradient Norm: 0.2024\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1420\u001b[0m\n",
      "\u001b[94mLoss: 0.958295 | Gradient Norm: 0.1666\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1430\u001b[0m\n",
      "\u001b[94mLoss: 0.779502 | Gradient Norm: 0.2297\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1440\u001b[0m\n",
      "\u001b[94mLoss: 0.868337 | Gradient Norm: 0.1182\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1450\u001b[0m\n",
      "\u001b[94mLoss: 0.891753 | Gradient Norm: 0.1756\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1460\u001b[0m\n",
      "\u001b[94mLoss: 0.813784 | Gradient Norm: 0.1410\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1470\u001b[0m\n",
      "\u001b[94mLoss: 0.794324 | Gradient Norm: 0.2369\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1480\u001b[0m\n",
      "\u001b[94mLoss: 0.664472 | Gradient Norm: 0.2004\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1490\u001b[0m\n",
      "\u001b[94mLoss: 0.755878 | Gradient Norm: 0.1291\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1500\u001b[0m\n",
      "\u001b[94mLoss: 0.932838 | Gradient Norm: 0.3022\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1510\u001b[0m\n",
      "\u001b[94mLoss: 0.757419 | Gradient Norm: 0.1386\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1520\u001b[0m\n",
      "\u001b[94mLoss: 0.743136 | Gradient Norm: 0.0904\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1530\u001b[0m\n",
      "\u001b[94mLoss: 0.795186 | Gradient Norm: 0.1737\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1540\u001b[0m\n",
      "\u001b[94mLoss: 0.918293 | Gradient Norm: 0.1569\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1550\u001b[0m\n",
      "\u001b[94mLoss: 0.902503 | Gradient Norm: 0.1364\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1560\u001b[0m\n",
      "\u001b[94mLoss: 0.812767 | Gradient Norm: 0.1402\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1570\u001b[0m\n",
      "\u001b[94mLoss: 0.860353 | Gradient Norm: 0.2132\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1575.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8606.\u001b[0m\n",
      "\u001b[93mNo improvement in validation loss. Current best: 0.8593.\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1580\u001b[0m\n",
      "\u001b[94mLoss: 0.914776 | Gradient Norm: 0.1581\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1590\u001b[0m\n",
      "\u001b[94mLoss: 0.822441 | Gradient Norm: 0.1784\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1600\u001b[0m\n",
      "\u001b[94mLoss: 0.764081 | Gradient Norm: 0.1427\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1610\u001b[0m\n",
      "\u001b[94mLoss: 0.701544 | Gradient Norm: 0.1225\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1620\u001b[0m\n",
      "\u001b[94mLoss: 0.841368 | Gradient Norm: 0.1993\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1630\u001b[0m\n",
      "\u001b[94mLoss: 1.299281 | Gradient Norm: 0.3311\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1640\u001b[0m\n",
      "\u001b[94mLoss: 0.749238 | Gradient Norm: 0.1061\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1650\u001b[0m\n",
      "\u001b[94mLoss: 0.908798 | Gradient Norm: 0.1554\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1660\u001b[0m\n",
      "\u001b[94mLoss: 0.890324 | Gradient Norm: 0.1621\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1670\u001b[0m\n",
      "\u001b[94mLoss: 0.829417 | Gradient Norm: 0.1572\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1680\u001b[0m\n",
      "\u001b[94mLoss: 0.841194 | Gradient Norm: 0.1320\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1690\u001b[0m\n",
      "\u001b[94mLoss: 0.722179 | Gradient Norm: 0.1394\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1700\u001b[0m\n",
      "\u001b[94mLoss: 0.708852 | Gradient Norm: 0.2040\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1710\u001b[0m\n",
      "\u001b[94mLoss: 0.780687 | Gradient Norm: 0.2416\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1720\u001b[0m\n",
      "\u001b[94mLoss: 1.097464 | Gradient Norm: 0.2155\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1730\u001b[0m\n",
      "\u001b[94mLoss: 0.806574 | Gradient Norm: 0.1503\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1740\u001b[0m\n",
      "\u001b[94mLoss: 0.736876 | Gradient Norm: 0.1700\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1750.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8595.\u001b[0m\n",
      "\u001b[93mNo improvement in validation loss. Current best: 0.8593.\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1750\u001b[0m\n",
      "\u001b[94mLoss: 0.765238 | Gradient Norm: 0.2362\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1760\u001b[0m\n",
      "\u001b[94mLoss: 0.898767 | Gradient Norm: 0.1980\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1770\u001b[0m\n",
      "\u001b[94mLoss: 0.791896 | Gradient Norm: 0.1733\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1780\u001b[0m\n",
      "\u001b[94mLoss: 0.865136 | Gradient Norm: 0.1525\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1790\u001b[0m\n",
      "\u001b[94mLoss: 0.744209 | Gradient Norm: 0.2771\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1800\u001b[0m\n",
      "\u001b[94mLoss: 0.860788 | Gradient Norm: 0.1869\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1810\u001b[0m\n",
      "\u001b[94mLoss: 0.750658 | Gradient Norm: 0.1920\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1820\u001b[0m\n",
      "\u001b[94mLoss: 0.818140 | Gradient Norm: 0.1437\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1830\u001b[0m\n",
      "\u001b[94mLoss: 1.496520 | Gradient Norm: 0.4241\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1840\u001b[0m\n",
      "\u001b[94mLoss: 0.728873 | Gradient Norm: 0.2312\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1850\u001b[0m\n",
      "\u001b[94mLoss: 1.404373 | Gradient Norm: 0.3798\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1860\u001b[0m\n",
      "\u001b[94mLoss: 1.018573 | Gradient Norm: 0.2782\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1870\u001b[0m\n",
      "\u001b[94mLoss: 0.884048 | Gradient Norm: 0.1498\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1880\u001b[0m\n",
      "\u001b[94mLoss: 0.703045 | Gradient Norm: 0.1777\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1890\u001b[0m\n",
      "\u001b[94mLoss: 0.671903 | Gradient Norm: 0.1552\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1900\u001b[0m\n",
      "\u001b[94mLoss: 0.884428 | Gradient Norm: 0.3307\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1910\u001b[0m\n",
      "\u001b[94mLoss: 0.824725 | Gradient Norm: 0.1524\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1920\u001b[0m\n",
      "\u001b[94mLoss: 0.775545 | Gradient Norm: 0.1352\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1925.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8576.\u001b[0m\n",
      "\u001b[92mNew best validation loss: 0.8576. Model checkpoint saved at checkpoints\\sssm-Walker2D-v1-model_step-1925-2024-11-18-22-01-56.pt.\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1930\u001b[0m\n",
      "\u001b[94mLoss: 0.665662 | Gradient Norm: 0.1809\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1940\u001b[0m\n",
      "\u001b[94mLoss: 0.743188 | Gradient Norm: 0.1489\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1950\u001b[0m\n",
      "\u001b[94mLoss: 0.820219 | Gradient Norm: 0.1264\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1960\u001b[0m\n",
      "\u001b[94mLoss: 0.749116 | Gradient Norm: 0.1366\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1970\u001b[0m\n",
      "\u001b[94mLoss: 0.853908 | Gradient Norm: 0.2417\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1980\u001b[0m\n",
      "\u001b[94mLoss: 0.651152 | Gradient Norm: 0.2322\u001b[0m\n",
      "\u001b[95m\n",
      "Step  1990\u001b[0m\n",
      "\u001b[94mLoss: 0.863038 | Gradient Norm: 0.1129\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2000\u001b[0m\n",
      "\u001b[94mLoss: 0.775725 | Gradient Norm: 0.1376\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2010\u001b[0m\n",
      "\u001b[94mLoss: 0.787756 | Gradient Norm: 0.1716\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2020\u001b[0m\n",
      "\u001b[94mLoss: 0.976819 | Gradient Norm: 0.2425\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2030\u001b[0m\n",
      "\u001b[94mLoss: 0.724633 | Gradient Norm: 0.1311\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2040\u001b[0m\n",
      "\u001b[94mLoss: 0.739254 | Gradient Norm: 0.1656\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2050\u001b[0m\n",
      "\u001b[94mLoss: 0.885655 | Gradient Norm: 0.1600\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2060\u001b[0m\n",
      "\u001b[94mLoss: 1.039898 | Gradient Norm: 0.1893\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2070\u001b[0m\n",
      "\u001b[94mLoss: 0.825614 | Gradient Norm: 0.2102\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2080\u001b[0m\n",
      "\u001b[94mLoss: 0.743223 | Gradient Norm: 0.1168\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2090\u001b[0m\n",
      "\u001b[94mLoss: 0.853913 | Gradient Norm: 0.1478\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 2100.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8591.\u001b[0m\n",
      "\u001b[93mNo improvement in validation loss. Current best: 0.8576.\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2100\u001b[0m\n",
      "\u001b[94mLoss: 0.922167 | Gradient Norm: 0.2738\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2110\u001b[0m\n",
      "\u001b[94mLoss: 0.902099 | Gradient Norm: 0.1515\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2120\u001b[0m\n",
      "\u001b[94mLoss: 1.257429 | Gradient Norm: 0.2884\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2130\u001b[0m\n",
      "\u001b[94mLoss: 0.812144 | Gradient Norm: 0.1355\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2140\u001b[0m\n",
      "\u001b[94mLoss: 0.878973 | Gradient Norm: 0.1334\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2150\u001b[0m\n",
      "\u001b[94mLoss: 0.812123 | Gradient Norm: 0.1369\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2160\u001b[0m\n",
      "\u001b[94mLoss: 0.723372 | Gradient Norm: 0.1365\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2170\u001b[0m\n",
      "\u001b[94mLoss: 0.767636 | Gradient Norm: 0.1391\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2180\u001b[0m\n",
      "\u001b[94mLoss: 0.702300 | Gradient Norm: 0.1107\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2190\u001b[0m\n",
      "\u001b[94mLoss: 0.767861 | Gradient Norm: 0.1231\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2200\u001b[0m\n",
      "\u001b[94mLoss: 0.639128 | Gradient Norm: 0.1265\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2210\u001b[0m\n",
      "\u001b[94mLoss: 0.955529 | Gradient Norm: 0.1287\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2220\u001b[0m\n",
      "\u001b[94mLoss: 1.087860 | Gradient Norm: 0.3711\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2230\u001b[0m\n",
      "\u001b[94mLoss: 0.794808 | Gradient Norm: 0.1030\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2240\u001b[0m\n",
      "\u001b[94mLoss: 0.745019 | Gradient Norm: 0.2317\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2250\u001b[0m\n",
      "\u001b[94mLoss: 0.766222 | Gradient Norm: 0.1519\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2260\u001b[0m\n",
      "\u001b[94mLoss: 0.673739 | Gradient Norm: 0.1861\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2270\u001b[0m\n",
      "\u001b[94mLoss: 0.768026 | Gradient Norm: 0.1943\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 2275.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8572.\u001b[0m\n",
      "\u001b[92mNew best validation loss: 0.8572. Model checkpoint saved at checkpoints\\sssm-Walker2D-v1-model_step-2275-2024-11-18-22-01-56.pt.\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2280\u001b[0m\n",
      "\u001b[94mLoss: 0.840432 | Gradient Norm: 0.1358\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2290\u001b[0m\n",
      "\u001b[94mLoss: 0.925182 | Gradient Norm: 0.1147\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2300\u001b[0m\n",
      "\u001b[94mLoss: 0.740603 | Gradient Norm: 0.1271\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2310\u001b[0m\n",
      "\u001b[94mLoss: 0.909275 | Gradient Norm: 0.2618\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2320\u001b[0m\n",
      "\u001b[94mLoss: 0.871656 | Gradient Norm: 0.1593\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2330\u001b[0m\n",
      "\u001b[94mLoss: 0.748672 | Gradient Norm: 0.1135\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2340\u001b[0m\n",
      "\u001b[94mLoss: 0.997436 | Gradient Norm: 0.2163\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2350\u001b[0m\n",
      "\u001b[94mLoss: 0.911530 | Gradient Norm: 0.1539\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2360\u001b[0m\n",
      "\u001b[94mLoss: 0.884388 | Gradient Norm: 0.1722\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2370\u001b[0m\n",
      "\u001b[94mLoss: 0.782540 | Gradient Norm: 0.2614\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2380\u001b[0m\n",
      "\u001b[94mLoss: 0.711949 | Gradient Norm: 0.1317\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2390\u001b[0m\n",
      "\u001b[94mLoss: 0.851547 | Gradient Norm: 0.1715\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2400\u001b[0m\n",
      "\u001b[94mLoss: 0.875698 | Gradient Norm: 0.1805\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2410\u001b[0m\n",
      "\u001b[94mLoss: 0.800286 | Gradient Norm: 0.1214\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2420\u001b[0m\n",
      "\u001b[94mLoss: 0.893475 | Gradient Norm: 0.1706\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2430\u001b[0m\n",
      "\u001b[94mLoss: 0.819447 | Gradient Norm: 0.2091\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2440\u001b[0m\n",
      "\u001b[94mLoss: 0.774641 | Gradient Norm: 0.2013\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 2450.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8559.\u001b[0m\n",
      "\u001b[92mNew best validation loss: 0.8559. Model checkpoint saved at checkpoints\\sssm-Walker2D-v1-model_step-2450-2024-11-18-22-01-56.pt.\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2450\u001b[0m\n",
      "\u001b[94mLoss: 1.062371 | Gradient Norm: 0.1323\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2460\u001b[0m\n",
      "\u001b[94mLoss: 0.904446 | Gradient Norm: 0.2060\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2470\u001b[0m\n",
      "\u001b[94mLoss: 0.820645 | Gradient Norm: 0.1122\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2480\u001b[0m\n",
      "\u001b[94mLoss: 0.852572 | Gradient Norm: 0.1557\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2490\u001b[0m\n",
      "\u001b[94mLoss: 0.928446 | Gradient Norm: 0.2421\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2500\u001b[0m\n",
      "\u001b[94mLoss: 0.863791 | Gradient Norm: 0.2723\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2510\u001b[0m\n",
      "\u001b[94mLoss: 0.617126 | Gradient Norm: 0.2199\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2520\u001b[0m\n",
      "\u001b[94mLoss: 0.797683 | Gradient Norm: 0.1272\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2530\u001b[0m\n",
      "\u001b[94mLoss: 0.687038 | Gradient Norm: 0.2004\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2540\u001b[0m\n",
      "\u001b[94mLoss: 0.851944 | Gradient Norm: 0.2518\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2550\u001b[0m\n",
      "\u001b[94mLoss: 0.795531 | Gradient Norm: 0.2358\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2560\u001b[0m\n",
      "\u001b[94mLoss: 0.752109 | Gradient Norm: 0.1213\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2570\u001b[0m\n",
      "\u001b[94mLoss: 0.921089 | Gradient Norm: 0.2080\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2580\u001b[0m\n",
      "\u001b[94mLoss: 1.010498 | Gradient Norm: 0.2777\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2590\u001b[0m\n",
      "\u001b[94mLoss: 0.821713 | Gradient Norm: 0.1660\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2600\u001b[0m\n",
      "\u001b[94mLoss: 0.711952 | Gradient Norm: 0.2596\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2610\u001b[0m\n",
      "\u001b[94mLoss: 0.822525 | Gradient Norm: 0.1701\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2620\u001b[0m\n",
      "\u001b[94mLoss: 0.868812 | Gradient Norm: 0.2476\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 2625.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8556.\u001b[0m\n",
      "\u001b[92mNew best validation loss: 0.8556. Model checkpoint saved at checkpoints\\sssm-Walker2D-v1-model_step-2625-2024-11-18-22-01-56.pt.\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2630\u001b[0m\n",
      "\u001b[94mLoss: 0.811536 | Gradient Norm: 0.1060\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2640\u001b[0m\n",
      "\u001b[94mLoss: 0.825008 | Gradient Norm: 0.1569\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2650\u001b[0m\n",
      "\u001b[94mLoss: 0.747161 | Gradient Norm: 0.2284\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2660\u001b[0m\n",
      "\u001b[94mLoss: 0.746298 | Gradient Norm: 0.1178\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2670\u001b[0m\n",
      "\u001b[94mLoss: 0.947679 | Gradient Norm: 0.2026\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2680\u001b[0m\n",
      "\u001b[94mLoss: 0.745872 | Gradient Norm: 0.1336\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2690\u001b[0m\n",
      "\u001b[94mLoss: 0.813754 | Gradient Norm: 0.1318\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2700\u001b[0m\n",
      "\u001b[94mLoss: 0.735201 | Gradient Norm: 0.1584\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2710\u001b[0m\n",
      "\u001b[94mLoss: 0.796043 | Gradient Norm: 0.1832\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2720\u001b[0m\n",
      "\u001b[94mLoss: 0.713440 | Gradient Norm: 0.1214\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2730\u001b[0m\n",
      "\u001b[94mLoss: 0.817902 | Gradient Norm: 0.1318\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2740\u001b[0m\n",
      "\u001b[94mLoss: 1.112567 | Gradient Norm: 0.2211\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2750\u001b[0m\n",
      "\u001b[94mLoss: 0.870771 | Gradient Norm: 0.1966\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2760\u001b[0m\n",
      "\u001b[94mLoss: 0.811543 | Gradient Norm: 0.2573\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2770\u001b[0m\n",
      "\u001b[94mLoss: 0.814032 | Gradient Norm: 0.1620\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2780\u001b[0m\n",
      "\u001b[94mLoss: 0.985791 | Gradient Norm: 0.1960\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2790\u001b[0m\n",
      "\u001b[94mLoss: 1.206038 | Gradient Norm: 0.2630\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 2800.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8561.\u001b[0m\n",
      "\u001b[93mNo improvement in validation loss. Current best: 0.8556.\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2800\u001b[0m\n",
      "\u001b[94mLoss: 0.739777 | Gradient Norm: 0.2804\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 2810.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.8533.\u001b[0m\n",
      "\u001b[92mNew best validation loss: 0.8533. Model checkpoint saved at checkpoints\\sssm-Walker2D-v1-model_step-2810-2024-11-18-22-01-56.pt.\u001b[0m\n",
      "\u001b[95m\n",
      "Step  2810\u001b[0m\n",
      "\u001b[94mLoss: 0.739908 | Gradient Norm: 0.1221\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "for epoch in range(num_epochs):\n",
    "    for step, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs,  targets = inputs.to(device), targets.to(device)\n",
    "        relative_step = epoch * steps_per_epoch + step\n",
    "        last_step = relative_step == num_steps - 1\n",
    "        # print(inputs.shape,  targets.shape)\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss,  metrics = loss_fn(outputs, targets)  # Assuming `loss_function` is defined\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # Backward pass and optimization step\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Clip global norm of gradient at 1.0, per the GPT-3 paper\n",
    "        grad_norms.append(grad_norm.item())\n",
    "        optimizer.step()\n",
    "\n",
    "        # Periodically evaluate the model on validation set\n",
    "        if relative_step % (eval_period // dilation) == 0 or last_step:\n",
    "            colored_print(\n",
    "                f\"\\nEvaluating the spectral SSM model at step {relative_step}.\",\n",
    "                Colors.OKCYAN,\n",
    "            )\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0.0\n",
    "                for val_inputs, val_targets in val_loader:\n",
    "                    val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                    val_outputs = model(val_inputs)\n",
    "                    loss, metrics = loss_fn(val_outputs, val_targets) \n",
    "                    val_loss += loss.item()\n",
    "                val_loss /= len(val_loader)\n",
    "                val_losses.append(val_loss)\n",
    "                val_time_steps.append(relative_step)\n",
    "            model.train()\n",
    "\n",
    "            colored_print(\n",
    "                f\"\\nValidation Loss: {val_loss:.4f}.\",\n",
    "                Colors.OKCYAN,\n",
    "            )\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_step = relative_step\n",
    "                patient_counter = 0\n",
    "\n",
    "                # Save model and optimizer state\n",
    "                model_checkpoint = f\"sssm-{controller}-model_step-{relative_step}-{timestamp}.pt\"\n",
    "               \n",
    "                model_path = os.path.join(checkpoint_dir, model_checkpoint)\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "\n",
    "                extra_info = f\"sssm-{controller}-other_step-{relative_step}-{timestamp}.pt\"\n",
    "                best_checkpoint =model_checkpoint, extra_info\n",
    "                extra_info_path = os.path.join(checkpoint_dir, extra_info)\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"optimizer\": optimizer.state_dict(),\n",
    "                        \"configs\": model.configs,\n",
    "                        \"step\": relative_step,\n",
    "                        \"val_loss\": val_loss,\n",
    "                        \"timestamp\": timestamp,\n",
    "                        \"rng_state_pytorch\": torch.get_rng_state(),\n",
    "                        \"rng_state_numpy\": np.random.get_state(),\n",
    "                        \"rng_state_cuda\": torch.cuda.get_rng_state_all()\n",
    "                        if torch.cuda.is_available()\n",
    "                        else None,\n",
    "                    },\n",
    "                    extra_info_path,\n",
    "                )\n",
    "                colored_print(\n",
    "                    f\"New best validation loss: {val_loss:.4f}. Model checkpoint saved at {model_path}.\",\n",
    "                    Colors.OKGREEN,\n",
    "                )\n",
    "            else:\n",
    "                patient_counter += 1\n",
    "                colored_print(\n",
    "                    f\"No improvement in validation loss. Current best: {best_val_loss:.4f}.\",\n",
    "                    Colors.WARNING,\n",
    "                )\n",
    "\n",
    "            if patient_counter >= patience:\n",
    "                colored_print(\n",
    "                    f\"Stopping early due to patience limit of {patience}.\",\n",
    "                    Colors.FAIL,\n",
    "                )\n",
    "                break\n",
    "\n",
    "        # Logging\n",
    "        if relative_step % 10 == 0:\n",
    "            colored_print(f\"\\nStep {relative_step:5d}\", Colors.HEADER)\n",
    "            colored_print(f\"Loss: {loss.item():.6f} | Gradient Norm: {grad_norm:.4f}\", Colors.OKBLUE)\n",
    "\n",
    "    if patient_counter >= patience:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model information for the spectral SSM model:\n",
      "    Best model at step 2810\n",
      "    Best validation loss: 0.8533\n",
      "    Best model checkpoint saved at: checkpoints\\sssm-Walker2D-v1-model_step-2810-2024-11-18-22-01-56.pt\n",
      "    Additional data saved at: checkpoints\\sssm-Walker2D-v1-other_step-2810-2024-11-18-22-01-56.pt\n",
      "Training details saved in training_details_sssm_2024-11-18-22-01-56.txt. Congratulations!\n",
      "Data saved to results\\mujoco-v1\\sssm\\sssm-Walker2D-v1-train_losses-2024-11-18-22-01-56.txt\n",
      "Data saved to results\\mujoco-v1\\sssm\\sssm-Walker2D-v1-val_losses-2024-11-18-22-01-56.txt\n",
      "Data saved to results\\mujoco-v1\\sssm\\sssm-Walker2D-v1-val_time_steps-2024-11-18-22-01-56.txt\n",
      "Data saved to results\\mujoco-v1\\sssm\\sssm-Walker2D-v1-grad_norms-2024-11-18-22-01-56.txt\n",
      "Training run completed. Results have been saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devan\\AppData\\Local\\Temp\\ipykernel_17000\\3573879908.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(best_model_path, map_location=\"cpu\")\n",
      "C:\\Users\\devan\\AppData\\Local\\Temp\\ipykernel_17000\\3573879908.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  other_data = torch.load(best_model_extra_info_path, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "from  train import save_results\n",
    "task = 'mujoco-v1'\n",
    "\n",
    "if best_checkpoint:\n",
    "    model_checkpoint, extra_info = best_checkpoint\n",
    "    best_model_path = os.path.join(checkpoint_dir, model_checkpoint)\n",
    "    best_model_extra_info_path = os.path.join(checkpoint_dir, extra_info)\n",
    "\n",
    "    # Load the best checkpoint\n",
    "    state_dict = torch.load(best_model_path, map_location=\"cuda\")\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    # Load optimizer and other data\n",
    "    other_data = torch.load(best_model_extra_info_path, map_location=\"cpu\")\n",
    "    optimizer.load_state_dict(other_data[\"optimizer\"])\n",
    "\n",
    "    # Display best model information\n",
    "    print(\"\\nBest model information for the spectral SSM model:\")\n",
    "    print(f\"    Best model at step {best_model_step}\")\n",
    "    print(f\"    Best validation loss: {best_val_loss:.4f}\")\n",
    "    print(f\"    Best model checkpoint saved at: {best_model_path}\")\n",
    "    print(f\"    Additional data saved at: {best_model_extra_info_path}\")\n",
    "\n",
    "    # Save training details to a file\n",
    "    training_details_path = f\"training_details_sssm_{timestamp}.txt\"\n",
    "    with open(training_details_path, \"w\") as f:\n",
    "        f.write(f\"Training completed for the spectral SSM on {task} at: {datetime.now()}\\n\")\n",
    "        f.write(f\"Best model step: {best_model_step}\\n\")\n",
    "        f.write(f\"Best validation loss: {best_val_loss:.4f}\\n\")\n",
    "        f.write(f\"Best model checkpoint saved at: {best_model_path}\\n\")\n",
    "        f.write(f\"Additional data saved at: {best_model_extra_info_path}\\n\")\n",
    "\n",
    "    print(f\"Training details saved in {training_details_path}. Congratulations!\")\n",
    "else:\n",
    "    print(\"\\nNo best checkpoint found. The model did not improve during training.\")\n",
    "\n",
    "# Save final results\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "if not os.path.exists(\"results/\"):\n",
    "    os.makedirs(\"results/\")\n",
    "if not os.path.exists(\"landscapes\"):\n",
    "    os.makedirs(\"landscapes\", exist_ok=True)\n",
    "\n",
    "save_results(task, controller, train_losses, \"train_losses\", timestamp)\n",
    "save_results(task, controller,val_losses, \"val_losses\", timestamp)\n",
    "save_results(task, controller, val_time_steps,\"val_time_steps\", timestamp)\n",
    "save_results(task, controller, grad_norms, \"grad_norms\", timestamp)\n",
    "\n",
    "print(\"Training run completed. Results have been saved.\")\n",
    "\n",
    "# from utils.loss_landscape import LossLandscape (takes 20 minutes to run)\n",
    "# #Don't exactly know how to visualize thi\n",
    "# loss_landscape = LossLandscape(model, device, optimizer, lr)\n",
    "# x_range = (-1, 1, 10)  # Adjust as needed\n",
    "# y_range = (-1, 1, 10)\n",
    "# loss_landscape.generate(\n",
    "#     train_loader,\n",
    "#     f\"landscapes/loss_landscape-{timestamp}\",\n",
    "#     x_range=x_range,\n",
    "#     y_range=y_range,\n",
    "#     plot_loss_landscape=True,\n",
    "#     plot_hessian=True,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSSM(\n",
       "  (loss_fn): MSELoss()\n",
       "  (emb): Linear(in_features=24, out_features=8, bias=False)\n",
       "  (stu): ModuleDict(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (hidden): ModuleList(\n",
       "      (0-1): 2 x Block(\n",
       "        (rn_1): RMSNorm((8,), eps=None, elementwise_affine=True)\n",
       "        (stu): STU(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (rn_2): RMSNorm((8,), eps=None, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (swiglu): SwiGLU(\n",
       "            (w): Linear(in_features=8, out_features=32, bias=False)\n",
       "            (v): Linear(in_features=8, out_features=32, bias=False)\n",
       "            (w2): Linear(in_features=32, out_features=8, bias=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (task_head): Linear(in_features=8, out_features=18, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  copy\n",
    "stu_layers = [copy.deepcopy(block.stu) for block in model.stu['hidden']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STU(\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stu_layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDS(nn.Module):\n",
    "    def __init__(self, state_dim, input_dim, output_dim):\n",
    "        super(LDS, self).__init__()\n",
    "        \n",
    "        self.d_out = output_dim\n",
    "\n",
    "        self.h0 = nn.Parameter(torch.randn(state_dim))\n",
    "        # self.A = nn.Parameter(torch.clip(torch.randn(state_dim), -.7, 0.7))\n",
    "        init_A = torch.randn(state_dim)\n",
    "        self.A = nn.Parameter(init_A/torch.max(torch.abs(init_A)))\n",
    "        self.B = nn.Parameter(torch.randn(input_dim, state_dim) / input_dim)\n",
    "        self.C = nn.Parameter(torch.randn(state_dim,output_dim) / state_dim)\n",
    "        self.D = nn.Parameter(torch.randn(input_dim,output_dim) / output_dim) #keep for more complex systems\n",
    "\n",
    "        self.M = nn.Parameter(torch.randn(output_dim, output_dim) / output_dim) #autoregressive\n",
    "    def forward(self, inputs):\n",
    "        bsz, seq_len, _ = inputs.shape\n",
    "        h_t = self.h0.expand(bsz, self.h0.shape[0]).to(device)  # Ensure h0 is on the correct device\n",
    "        outputs = []\n",
    "        A = self.A.flatten()\n",
    "\n",
    "        # Store all intermediate h_t states\n",
    "        all_h_t = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            u_t = inputs[:, t, :]  # Get input for all batches at time t\n",
    "            h_t = A * h_t + u_t @ self.B  # Update hidden states for all batches\n",
    "            all_h_t.append(h_t.unsqueeze(1))  # Store the updated h_t for each time step\n",
    "\n",
    "        # Concatenate all h_t states along the time dimension\n",
    "        all_h_t = torch.cat(all_h_t, dim=1)\n",
    "\n",
    "        # Apply C to all concatenated h_t states at once\n",
    "        outputs = torch.matmul(all_h_t, self.C)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def compute_loss(self, inputs, targets):\n",
    "        mse_loss = nn.MSELoss()\n",
    "        outputs = self(inputs)\n",
    "        return mse_loss(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GeneralLDS(nn.Module):\n",
    "    def __init__(self, state_dim, input_dim, output_dim):\n",
    "        super(GeneralLDS, self).__init__()\n",
    "        \n",
    "        self.d_out = output_dim\n",
    "\n",
    "        self.h0 = nn.Parameter(torch.randn(state_dim))\n",
    "        # Initialize A as a full matrix\n",
    "        init_A = torch.randn(state_dim, state_dim) / input_dim \n",
    "        max_evec = torch.max(torch.abs(torch.linalg.eigvals(init_A)))\n",
    "        self.A = nn.Parameter(init_A / (max_evec * state_dim))\n",
    "        self.B = nn.Parameter(torch.randn(input_dim, state_dim) / input_dim)\n",
    "        self.C = nn.Parameter(torch.randn(state_dim, output_dim) / state_dim)\n",
    "        self.D = nn.Parameter(torch.randn(input_dim, output_dim) / output_dim) # Optional for more complex systems\n",
    "\n",
    "        self.M = nn.Parameter(torch.randn(output_dim, output_dim) / output_dim) # Optional autoregressive component\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        bsz, seq_len, _ = inputs.shape\n",
    "        h_t = self.h0.expand(bsz, -1).to(inputs.device)  # Ensure h0 is on the correct device\n",
    "        outputs = []\n",
    "        \n",
    "        # Process each time step\n",
    "        for t in range(seq_len):\n",
    "            u_t = inputs[:, t, :]  # Get input for all batches at time t\n",
    "            h_t = torch.matmul(h_t, self.A) + torch.matmul(u_t, self.B)  # Update hidden states using full matrix A\n",
    "            outputs.append(torch.matmul(h_t, self.C).unsqueeze(1))  # Calculate output and store\n",
    "\n",
    "        # Concatenate outputs along the time dimension\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_loss(self, inputs, targets):\n",
    "        mse_loss = nn.MSELoss()\n",
    "        outputs = self(inputs)\n",
    "        return mse_loss(outputs, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD_LDS(nn.Module):\n",
    "    def __init__(self, state_dim, input_dim, output_dim):\n",
    "        super(SVD_LDS, self).__init__()\n",
    "        \n",
    "        self.d_out = output_dim\n",
    "\n",
    "        self.h0 = nn.Parameter(torch.randn(state_dim))\n",
    "        \n",
    "        # Initialize A as a full matrix and perform SVD\n",
    "        init_A = torch.randn(state_dim, state_dim) / input_dim \n",
    "        U, S, V = torch.linalg.svd(init_A, full_matrices=False)\n",
    "        S_clamped = torch.clamp(S, max=1.0)  # Clamp the singular values\n",
    "\n",
    "        # Store SVD components as parameters\n",
    "        self.U = nn.Parameter(U)\n",
    "        self.S = nn.Parameter(S_clamped)\n",
    "        self.V = nn.Parameter(V)\n",
    "\n",
    "        self.B = nn.Parameter(torch.randn(input_dim, state_dim) / input_dim)\n",
    "        self.C = nn.Parameter(torch.randn(state_dim, output_dim) / state_dim)\n",
    "        self.D = nn.Parameter(torch.randn(input_dim, output_dim) / output_dim)  # Optional\n",
    "\n",
    "        self.M = nn.Parameter(torch.randn(output_dim, output_dim) / output_dim)  # Optional\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        bsz, seq_len, _ = inputs.shape\n",
    "        h_t = self.h0.expand(bsz, -1).to(inputs.device)  # Ensure h0 is on the correct device\n",
    "        outputs = []\n",
    "        \n",
    "        # Normalize columns of U and rows of V\n",
    "        U_norm = torch.nn.functional.normalize(self.U, p=2, dim=0)\n",
    "        V_norm = torch.nn.functional.normalize(self.V, p=2, dim=1)\n",
    "        \n",
    "        # Reconstruct A using normalized U, S, and V\n",
    "        A = U_norm @ torch.diag(self.S) @ V_norm.t()\n",
    "\n",
    "        # Process each time step\n",
    "        for t in range(seq_len):\n",
    "            u_t = inputs[:, t, :]  # Get input for all batches at time t\n",
    "            h_t = torch.matmul(h_t, A) + torch.matmul(u_t, self.B)  # Update hidden states using A\n",
    "            outputs.append(torch.matmul(h_t, self.C).unsqueeze(1))  # Calculate output and store\n",
    "\n",
    "        # Concatenate outputs along the time dimension\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_loss(self, inputs, targets):\n",
    "        mse_loss = nn.MSELoss()\n",
    "        outputs = self(inputs)\n",
    "        return mse_loss(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 8])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randn(1, sl, n_embd).to(device)\n",
    "stu_layers[0](inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSSM(\n",
       "  (loss_fn): MSELoss()\n",
       "  (emb): Linear(in_features=24, out_features=8, bias=False)\n",
       "  (stu): ModuleDict(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (hidden): ModuleList(\n",
       "      (0-1): 2 x Block(\n",
       "        (rn_1): RMSNorm((8,), eps=None, elementwise_affine=True)\n",
       "        (stu): STU(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (rn_2): RMSNorm((8,), eps=None, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (swiglu): SwiGLU(\n",
       "            (w): Linear(in_features=8, out_features=32, bias=False)\n",
       "            (v): Linear(in_features=8, out_features=32, bias=False)\n",
       "            (w2): Linear(in_features=32, out_features=8, bias=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (task_head): Linear(in_features=8, out_features=18, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.475245475769043\n",
      "Epoch 100, Loss: 1.2763808965682983\n",
      "Epoch 200, Loss: 1.0696425437927246\n",
      "Epoch 300, Loss: 0.8730352520942688\n",
      "Epoch 400, Loss: 0.6907178163528442\n",
      "Epoch 500, Loss: 0.5526415109634399\n",
      "Epoch 600, Loss: 0.45476576685905457\n",
      "Epoch 700, Loss: 0.38495343923568726\n",
      "Epoch 800, Loss: 0.3613731265068054\n",
      "Epoch 900, Loss: 0.3310360908508301\n",
      "Epoch 1000, Loss: 0.2923634648323059\n",
      "Epoch 1100, Loss: 0.2645423412322998\n",
      "Epoch 1200, Loss: 0.2672020196914673\n",
      "Epoch 1300, Loss: 0.23167333006858826\n",
      "Epoch 1400, Loss: 0.24478840827941895\n",
      "Epoch 1500, Loss: 0.22030484676361084\n",
      "Epoch 1600, Loss: 0.21254920959472656\n",
      "Epoch 1700, Loss: 0.20849984884262085\n",
      "Epoch 1800, Loss: 0.2151995599269867\n",
      "Epoch 1900, Loss: 0.18463021516799927\n",
      "Epoch 2000, Loss: 0.18979063630104065\n",
      "Epoch 2100, Loss: 0.1804930865764618\n",
      "Epoch 2200, Loss: 0.20763355493545532\n",
      "Epoch 2300, Loss: 0.17175938189029694\n",
      "Epoch 2400, Loss: 0.17952224612236023\n",
      "Epoch 2500, Loss: 0.16539375483989716\n",
      "Epoch 2600, Loss: 0.15265661478042603\n",
      "Epoch 2700, Loss: 0.16828115284442902\n",
      "Epoch 2800, Loss: 0.14839422702789307\n",
      "Epoch 2900, Loss: 0.15279005467891693\n",
      "Epoch 3000, Loss: 0.14296364784240723\n",
      "Epoch 3100, Loss: 0.12901571393013\n",
      "Epoch 3200, Loss: 0.12496776133775711\n",
      "Epoch 3300, Loss: 0.1327342391014099\n",
      "Epoch 3400, Loss: 0.13451942801475525\n",
      "Epoch 3500, Loss: 0.13182365894317627\n",
      "Epoch 3600, Loss: 0.12031644582748413\n",
      "Epoch 3700, Loss: 0.1322832703590393\n",
      "Epoch 3800, Loss: 0.12109407782554626\n",
      "Epoch 3900, Loss: 0.11889591068029404\n",
      "Epoch 4000, Loss: 0.12082468718290329\n",
      "Epoch 4100, Loss: 0.13144363462924957\n",
      "Epoch 4200, Loss: 0.11169672757387161\n",
      "Epoch 4300, Loss: 0.12040719389915466\n",
      "Epoch 4400, Loss: 0.12383968383073807\n",
      "Epoch 4500, Loss: 0.11987335979938507\n",
      "Epoch 4600, Loss: 0.11258985847234726\n",
      "Epoch 4700, Loss: 0.11295405775308609\n",
      "Epoch 4800, Loss: 0.1175704300403595\n",
      "Epoch 4900, Loss: 0.11488965153694153\n"
     ]
    }
   ],
   "source": [
    "state_dim = 100 #@param\n",
    "lds =  LDS(state_dim, n_embd, n_embd).to(device)\n",
    "optimizer = torch.optim.Adam(lds.parameters(), lr = 0.0001)\n",
    "lds_epochs = 5000\n",
    "lds_loss_values = []\n",
    "\n",
    "for epoch in range(lds_epochs):\n",
    "    inputs = torch.randn(1, sl, n_embd).to(device)\n",
    "    stu_outputs = stu_layers[0](inputs).to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = lds.compute_loss(inputs, stu_outputs)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(lds.parameters(), max_norm=1)\n",
    "    lds_loss_values.append(loss.item())\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lds.A.data.clamp_(max=1, min = -1)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-0.6609, device='cuda:0'),\n",
       " tensor(-0.6373, device='cuda:0'),\n",
       " tensor(-0.5924, device='cuda:0'),\n",
       " tensor(-0.5916, device='cuda:0'),\n",
       " tensor(-0.5861, device='cuda:0'),\n",
       " tensor(-0.5778, device='cuda:0'),\n",
       " tensor(-0.5531, device='cuda:0'),\n",
       " tensor(-0.5431, device='cuda:0'),\n",
       " tensor(-0.5245, device='cuda:0'),\n",
       " tensor(-0.5188, device='cuda:0'),\n",
       " tensor(-0.5103, device='cuda:0'),\n",
       " tensor(-0.4762, device='cuda:0'),\n",
       " tensor(-0.4741, device='cuda:0'),\n",
       " tensor(-0.4608, device='cuda:0'),\n",
       " tensor(-0.4463, device='cuda:0'),\n",
       " tensor(-0.4426, device='cuda:0'),\n",
       " tensor(-0.3977, device='cuda:0'),\n",
       " tensor(-0.2577, device='cuda:0'),\n",
       " tensor(-0.2451, device='cuda:0'),\n",
       " tensor(-0.1992, device='cuda:0'),\n",
       " tensor(-0.1866, device='cuda:0'),\n",
       " tensor(-0.1497, device='cuda:0'),\n",
       " tensor(-0.1131, device='cuda:0'),\n",
       " tensor(-0.1129, device='cuda:0'),\n",
       " tensor(-0.0971, device='cuda:0'),\n",
       " tensor(-0.0791, device='cuda:0'),\n",
       " tensor(-0.0759, device='cuda:0'),\n",
       " tensor(-0.0754, device='cuda:0'),\n",
       " tensor(-0.0699, device='cuda:0'),\n",
       " tensor(-0.0543, device='cuda:0'),\n",
       " tensor(-0.0328, device='cuda:0'),\n",
       " tensor(-0.0279, device='cuda:0'),\n",
       " tensor(-0.0259, device='cuda:0'),\n",
       " tensor(-0.0035, device='cuda:0'),\n",
       " tensor(-0.0028, device='cuda:0'),\n",
       " tensor(0.0030, device='cuda:0'),\n",
       " tensor(0.0304, device='cuda:0'),\n",
       " tensor(0.0441, device='cuda:0'),\n",
       " tensor(0.0470, device='cuda:0'),\n",
       " tensor(0.0540, device='cuda:0'),\n",
       " tensor(0.0560, device='cuda:0'),\n",
       " tensor(0.0635, device='cuda:0'),\n",
       " tensor(0.0826, device='cuda:0'),\n",
       " tensor(0.1008, device='cuda:0'),\n",
       " tensor(0.1023, device='cuda:0'),\n",
       " tensor(0.1215, device='cuda:0'),\n",
       " tensor(0.1271, device='cuda:0'),\n",
       " tensor(0.1412, device='cuda:0'),\n",
       " tensor(0.1488, device='cuda:0'),\n",
       " tensor(0.1514, device='cuda:0'),\n",
       " tensor(0.1568, device='cuda:0'),\n",
       " tensor(0.1597, device='cuda:0'),\n",
       " tensor(0.1714, device='cuda:0'),\n",
       " tensor(0.1760, device='cuda:0'),\n",
       " tensor(0.1839, device='cuda:0'),\n",
       " tensor(0.1987, device='cuda:0'),\n",
       " tensor(0.2112, device='cuda:0'),\n",
       " tensor(0.2128, device='cuda:0'),\n",
       " tensor(0.2335, device='cuda:0'),\n",
       " tensor(0.2389, device='cuda:0'),\n",
       " tensor(0.2530, device='cuda:0'),\n",
       " tensor(0.2592, device='cuda:0'),\n",
       " tensor(0.2734, device='cuda:0'),\n",
       " tensor(0.2898, device='cuda:0'),\n",
       " tensor(0.2965, device='cuda:0'),\n",
       " tensor(0.2982, device='cuda:0'),\n",
       " tensor(0.2992, device='cuda:0'),\n",
       " tensor(0.3078, device='cuda:0'),\n",
       " tensor(0.3175, device='cuda:0'),\n",
       " tensor(0.3328, device='cuda:0'),\n",
       " tensor(0.3450, device='cuda:0'),\n",
       " tensor(0.3458, device='cuda:0'),\n",
       " tensor(0.3479, device='cuda:0'),\n",
       " tensor(0.3524, device='cuda:0'),\n",
       " tensor(0.3706, device='cuda:0'),\n",
       " tensor(0.3794, device='cuda:0'),\n",
       " tensor(0.3905, device='cuda:0'),\n",
       " tensor(0.3962, device='cuda:0'),\n",
       " tensor(0.3976, device='cuda:0'),\n",
       " tensor(0.4573, device='cuda:0'),\n",
       " tensor(0.4663, device='cuda:0'),\n",
       " tensor(0.4742, device='cuda:0'),\n",
       " tensor(0.4802, device='cuda:0'),\n",
       " tensor(0.4950, device='cuda:0'),\n",
       " tensor(0.5053, device='cuda:0'),\n",
       " tensor(0.5082, device='cuda:0'),\n",
       " tensor(0.5355, device='cuda:0'),\n",
       " tensor(0.5695, device='cuda:0'),\n",
       " tensor(0.5727, device='cuda:0'),\n",
       " tensor(0.6008, device='cuda:0'),\n",
       " tensor(0.6088, device='cuda:0'),\n",
       " tensor(0.6122, device='cuda:0'),\n",
       " tensor(0.6194, device='cuda:0'),\n",
       " tensor(0.6326, device='cuda:0'),\n",
       " tensor(0.6815, device='cuda:0'),\n",
       " tensor(0.7101, device='cuda:0'),\n",
       " tensor(0.7292, device='cuda:0'),\n",
       " tensor(0.8482, device='cuda:0'),\n",
       " tensor(0.8527, device='cuda:0'),\n",
       " tensor(0.9338, device='cuda:0')]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(lds.A.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import my code over for visualizing the STU kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bfb6ec1b40>]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEMUlEQVR4nO3deVxU5f4H8M8MywCyicgqCu7iAgiJpC0mZuq1/eZVf+ml0mtZt6LbgpamldhmVteyLLW6uZSlVq6EIlmkieIuqKCgrIow7MvM8/uDnByZAQZn5swwn/frNa8XnPOcM9858Wo+Pud5niMTQggQERERSUQudQFERERk2xhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSdlLXUBbqNVq5Ofnw83NDTKZTOpyiIiIqA2EEKioqEBAQADkcv39H1YRRvLz8xEUFCR1GURERNQOeXl56Natm979VhFG3NzcADR9GHd3d4mrISIiorZQKpUICgrSfI/rYxVh5OqtGXd3d4YRIiIiK9PaEAsOYCUiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKZsPI5mFFfjsl2zUN6qlLoWIiMgmWcVTe01p7NJUAECDSuDx23tJXA0REZHtsfmekauOXiyTugQiIiKbxDBCREREkmIYISIiIkkxjBAREZGkDA4jqampmDhxIgICAiCTybBp06ZWj6mrq8PcuXPRo0cPKBQKBAcHY+XKle2pl4iIiDoYg2fTVFVVISwsDI888gjuv//+Nh3z0EMPoaioCJ9//jl69+6NgoICqNWcSktERETtCCPjxo3DuHHj2tx++/bt2LNnD7Kzs+Hl5QUACA4ONvRtTU4GmdQlEBER2SSTjxn54YcfEBUVhbfeeguBgYHo27cv/vOf/6CmpkbvMXV1dVAqlVovUxMQJn8PIiIias7ki55lZ2dj7969cHJywsaNG3Hp0iU88cQTuHz5MlatWqXzmMTERCxYsMDUpeHClWqTvwcRERG1zOQ9I2q1GjKZDF9//TWGDRuG8ePHY8mSJfjiiy/09o4kJCSgvLxc88rLyzNJbcUVdZqfeZuGiIhIGibvGfH390dgYCA8PDw02wYMGAAhBC5cuIA+ffo0O0ahUEChUJi6NMYPIiIiC2DynpERI0YgPz8flZWVmm1ZWVmQy+Xo1q2bqd++zThmhIiISBoGh5HKykpkZGQgIyMDAJCTk4OMjAzk5uYCaLrFMm3aNE37KVOmoEuXLoiLi8OJEyeQmpqK559/Ho888gicnZ2N8ynaSX1N/hDMIkRERJIwOIwcOHAAERERiIiIAADEx8cjIiIC8+bNAwAUFBRoggkAuLq6IikpCWVlZYiKisLUqVMxceJEfPDBB0b6CO33Zdo5zc9qphEiIiJJGDxm5Pbbb4do4Yt79erVzbb1798fSUlJhr6Vye08XqT5Wc0sQkREJAmbfjaNnfyvIaxCCJRV16OmXiVhRURERLaHYeRPV6obEL4wCUNfs7weHCIioo7MpsOI/TVh5HBeGQCgpoE9I0REROZk02FEfk0Y4QBWIiIiadh0GLHXCiMSFkJERGTDbDqMyGVcg5WIiEhqth1GbPrTExERWQab/jq2Y88IERGR5Gw6jMgYRoiIiCRn22FE6gKIiIjItsMI0wgREZH0bDqMMIsQERFJz6bDSG8fV6lLICIisnk2HUYGBnhIXQIREZHNs+kwsiQpS+d2waXhiYiIzMamw4g+zCJERETmwzCiQ3FFHVR8WA0REZFZMIzoMDwxGdNX7pe6DCIiIpvAMKLH3jOXpC6BiIjIJjCMEBERkaQYRoiIiEhSNh1GnB3spC6BiIjI5tl0GOFDe4mIiKRn02HE0d6mPz4REZFFsOlv48+n3yR1CURERDbPpsNIZI/OUpdARERk82w6jBAREZH0bD6MPBTVTeoSiIiIbJrNhxEZOKWGiIhISjYfRoiIiEhaNh9GWlprJHHrSQjBp/cSERGZks2HkZZ8kpqNn08WS10GERFRh2ZwGElNTcXEiRMREBAAmUyGTZs2tfnYX3/9Ffb29ggPDzf0bU2mtVVYTxYozVMIERGRjTI4jFRVVSEsLAzLli0z6LiysjJMmzYNo0ePNvQtTWrmrb1a3L8kKctMlRAREdkme0MPGDduHMaNG2fwG82aNQtTpkyBnZ2dQb0pphbi3Ql3hwXgh8P5UpdCRERkk8wyZmTVqlXIzs7G/Pnz29S+rq4OSqVS62VKilaeUcNBrERERKZj8jBy+vRpvPTSS/jf//4He/u2dcQkJibCw8ND8woKCjJxlS1b/ds5Sd+fiIioIzNpGFGpVJgyZQoWLFiAvn37tvm4hIQElJeXa155eXkmrBKI6dWlxf0LfjyB4opak9ZARERkq0waRioqKnDgwAE8+eSTsLe3h729PRYuXIjDhw/D3t4eu3bt0nmcQqGAu7u71suU7g0PbLXN3tOXTFoDERGRrTJ4AKsh3N3dcfToUa1tH330EXbt2oUNGzYgJCTElG/fZnJ560vCtzYFmIiIiNrH4DBSWVmJM2fOaH7PyclBRkYGvLy80L17dyQkJODixYv48ssvIZfLMWjQIK3jfXx84OTk1Gw7ERER2SaDw8iBAwcwatQoze/x8fEAgOnTp2P16tUoKChAbm6u8SokIiKiDk0mrGDeqlKphIeHB8rLy002fuTWt3Yjt7Ra7/6lk8Jxb0TrY0uIiIioSVu/v/lsmj9tffqWFvdzzAgREZFpMIz8yVVh0rG8REREpAfDCBEREUmKYYSIiIgkxTByDUc7/ZdDxkEjREREJsEwco2M+WOkLoGIiMjmMIxcw8VR/yDWf689hPKaBjNWQ0REZBsYRgywcm+O1CUQERF1OAwjBqhrVEtdAhERUYfDMHKdsCBPvfsELH6xWiIiIqvDMHKdp0b11r+TWYSIiMjoGEYM8ElqttQlEBERdTgMI9dprfPjZIHSLHUQERHZCoYRA417/xepSyAiIupQGEau4+JoJ3UJRERENoVh5DoxPbu02kYIjmQlIiIyFoaR68jlMoR4d2qxDbMIERGR8TCM6PD06D4t7lcxjRARERkNw4gO90YEYuezt+rdr2YYISIiMhqGET36+rrp3afmqvBERERGwzDSDuwZISIiMh6GkXbgmBEiIiLjYRhph3+vPYRiZa3UZRAREXUIDCPtkJJZgjkbj0pdBhERUYfAMNJO5y9XS10CERFRh8Aw0k5ymUzqEoiIiDoEhpEWfDA5Qu8+ZhEiIiLjYBhpQai/u9597BkhIiIyDoaRdpLzyhERERkFv1LbSQb2jBARERkDw0iL9C9uJmcWISIiMgqGkRaEeLvq3SfjmBEiIiKjYBhpgZ1chkdHhujcx54RIiIi4zA4jKSmpmLixIkICAiATCbDpk2bWmz//fffY8yYMejatSvc3d0RExODHTt2tLdes9MXOg7mlqFRxcf3EhER3SiDw0hVVRXCwsKwbNmyNrVPTU3FmDFjsHXrVqSnp2PUqFGYOHEiDh06ZHCxUojp1UXvvu8PXTRjJURERB2TvaEHjBs3DuPGjWtz+6VLl2r9vmjRImzevBk//vgjIiL0LypmKUb188FtfbtiT1ZJs30lFXUSVERERNSxmH3MiFqtRkVFBby8vPS2qaurg1Kp1HpJRSaTYfQAH537hNA/24aIiIjaxuxh5J133kFlZSUeeughvW0SExPh4eGheQUFBZmxwub0rbbKISNEREQ3zqxhZM2aNViwYAG++eYb+Pjo7m0AgISEBJSXl2teeXl5ZqyyOTs9o1jV7BkhIiK6YQaPGWmvdevW4bHHHsO3336L2NjYFtsqFAooFAozVdY6fWHkYO4VM1dCRETU8ZilZ2Tt2rWIi4vD2rVrMWHCBHO8pVn8cvoSdhwvxNmSSqlLISIisloG94xUVlbizJkzmt9zcnKQkZEBLy8vdO/eHQkJCbh48SK+/PJLAE23ZqZPn473338f0dHRKCwsBAA4OzvDw8PDSB9DOv/6Kh0AcG5xxwlZRERE5mRwz8iBAwcQERGhmZYbHx+PiIgIzJs3DwBQUFCA3NxcTftPP/0UjY2NmD17Nvz9/TWvp59+2kgfwfSGdveUugQiIqIOy+Cekdtvv73FKa2rV6/W+j0lJcXQt7A4vX3cpC6BiIiow+KzaYiIiEhSDCNEREQkKYaRNlo7YzicHHi5iIiIjI3frm0U06sLUl8YJXUZREREHQ7DiAF83Jzg7qR7zG9do8rM1RAREXUMDCMGGhSoe22Uw3nlZq6EiIioY2AYMRAfR0NERGRcDCMG4sPxiIiIjIthxED6ssiPh/PNWwgREVEHwTBiIH09I1/9ft7MlRAREXUMDCMG4m0aIiIi42IYMRCjCBERkXExjBhowmB/qUsgIiLqUBhGDBQ3IkTqEoiIiDoUhhED2cllUpdARETUoTCMGFGRshYqNUeVEBERGYJhxIiiFyXj0S/+kLoMIiIiq8IwYmQpmSVSl0BERGRVGEaIiIhIUgwjREREJCmGkXbYMCtG6hKIiIg6DIaRdogK9pK6BCIiog6DYaSdtv77Fr37qusbzVgJERGRdWMYaafQAHe9+5b+fNqMlRAREVk3hpEbMKpfV53bD+eVmbcQIiIiK8YwcgOWTR2qc7vgIqxERERtxjByA1wc7XVuVzGNEBERtRnDiAk08vk0REREbcYwYgKCPSNERERtxjBiAnxyLxERUdsxjJgAwwgREVHbMYzcoGVTms+oOVVYgdB521FcUStBRURERNbF4DCSmpqKiRMnIiAgADKZDJs2bWr1mJSUFAwdOhQKhQK9e/fG6tWr21GqZboppLPO7dX1Kryx5aSZqyEiIrI+BoeRqqoqhIWFYdmyZW1qn5OTgwkTJmDUqFHIyMjAM888g8ceeww7duwwuFhrc7myXuoSiIiILJ7uhTJaMG7cOIwbN67N7ZcvX46QkBC8++67AIABAwZg7969eO+99zB27FhD397itDRxpkGlNl8hREREVsrkY0bS0tIQGxurtW3s2LFIS0vTe0xdXR2USqXWy1KpW0gjtY0MI0RERK0xeRgpLCyEr6+v1jZfX18olUrU1NToPCYxMREeHh6aV1BQkKnLbDe5TKZ3X2lVnRkrISIisk4WOZsmISEB5eXlmldeXp7UJenl6+6kdx/XPiMiImqdwWNGDOXn54eioiKtbUVFRXB3d4ezs7POYxQKBRQKhalLMzmGESIiotaZvGckJiYGycnJWtuSkpIQExNj6reW3MUy3behiIiI6C8Gh5HKykpkZGQgIyMDQNPU3YyMDOTm5gJousUybdo0TftZs2YhOzsbL7zwAk6dOoWPPvoI33zzDZ599lnjfAILl89AQkRE1CKDw8iBAwcQERGBiIgIAEB8fDwiIiIwb948AEBBQYEmmABASEgItmzZgqSkJISFheHdd9/FZ5991iGm9bbFlWquNUJERNQSmbCCR8wqlUp4eHigvLwc7u7uUpfTTPBLW/TumzwsCIn3DzFjNURERJahrd/fFjmbxtosnRSud19Nvcp8hRAREVkhhhEjuDciEJtmj9C5r6V1SIiIiIhhxGjCgzx1bpcxjBAREbWIYcTEDuVdkboEIiIii8YwYmLZJVVSl0BERGTRGEaMKDrES+oSiIiIrA7DiBEpHOx0bt9xvNDMlRAREVkPhhEjCu/moXP7v75KR3lNg5mrISIisg4MI0b0xKjeevelZBabsRIiIiLrwTBiRE4Odvg5/lad+17eeMzM1RAREVkHhhEj6+3jpnsHlxshIiLSiWHETLgSKxERkW4MI2bCAaxERES6MYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMOICSQ9q3utESIiImqOYcQE+vjqXmtk3f5c1DaozFwNERGRZWMYMaOXvj+KuFV/SF0GERGRRWEYMZF/36H7OTVp2ZfNXAkREZFlYxgxkZCunaQugYiIyCowjJiIWi11BURERNaBYcRE1ELo3VesrDVjJURERJaNYcREWsgimLzid/MVQkREZOEYRkykpZ6RsyVVZqyEiIjIsjGMmMgdA3ykLoGIiMgqMIyYiI+bk9QlEBERWQWGESIiIpIUw4hETuQrpS6BiIjIIjCMmNDbDw7Ru2/8B7/gdFGFGashIiKyTAwjJvT3qCCM7q9/IOuB81fMWA0REZFlYhgxMSdHO6lLICIismjtCiPLli1DcHAwnJycEB0djf3797fYfunSpejXrx+cnZ0RFBSEZ599FrW1trEK6R39OMWXiIioJQaHkfXr1yM+Ph7z58/HwYMHERYWhrFjx6K4uFhn+zVr1uCll17C/PnzcfLkSXz++edYv3495syZc8PFW4P7hwbq3SczYx1ERESWyuAwsmTJEsyYMQNxcXEIDQ3F8uXL4eLigpUrV+ps/9tvv2HEiBGYMmUKgoODceedd2Ly5Mmt9qZ0FDKZDAMD3HXu23+u1MzVEBERWR6Dwkh9fT3S09MRGxv71wnkcsTGxiItLU3nMTfffDPS09M14SM7Oxtbt27F+PHj9b5PXV0dlEql1suaBXo669z+/cGLZq6EiIjI8hgURi5dugSVSgVfX1+t7b6+vigsLNR5zJQpU7Bw4UKMHDkSDg4O6NWrF26//fYWb9MkJibCw8ND8woKCjKkTIvz+r2DpC6BiIjIYpl8Nk1KSgoWLVqEjz76CAcPHsT333+PLVu24LXXXtN7TEJCAsrLyzWvvLw8U5dpUj7uXBqeiIhIH3tDGnt7e8POzg5FRUVa24uKiuDn56fzmFdeeQUPP/wwHnvsMQDA4MGDUVVVhZkzZ2Lu3LmQy5vnIYVCAYVCYUhpREREZKUM6hlxdHREZGQkkpOTNdvUajWSk5MRExOj85jq6upmgcPOrmntDSGEofVarc+nR0ldAhERkUUyqGcEAOLj4zF9+nRERUVh2LBhWLp0KaqqqhAXFwcAmDZtGgIDA5GYmAgAmDhxIpYsWYKIiAhER0fjzJkzeOWVVzBx4kRNKLEFd+hZibW2QQUnB9u5DkRERNczOIxMmjQJJSUlmDdvHgoLCxEeHo7t27drBrXm5uZq9YS8/PLLkMlkePnll3Hx4kV07doVEydOxBtvvGG8T2EFZDLdq4qEL9yJkwvv0rufiIioo5MJK7hXolQq4eHhgfLycri7616zwxoEv7RF5/bsReMhlzOMEBFRx9LW728+m8YCqC0/DxIREZkMw4gFUDGMEBGRDWMYsQAj39wtdQlERESSYRgxI33LwpdU1NnUNGciIqJrMYyY0RePDNO7T6VmGCEiItvEMGJGvX1cEdOzi859L2w4YuZqiIiILAPDiJmtirsJ/f3cmm3//hCf4EtERLaJYcTMnBzssGbGcKnLICIishgMIxLw6uSoczsHsRIRkS1iGLEgT609JHUJREREZscwYkF+OlIgdQlERERmxzBCREREkmIYISIiIkkxjFgYDmIlIiJbwzAikV9eGKVzeyNXYiUiIhvDMCKRIC8XndvTzl5Gg0pt5mqIiIikwzBiYaat3I/EraekLoOIiMhsGEYs0Mpfc7DzeKHUZRAREZkFw4iFmvlVutQlEBERmQXDiAVLySyWugQiIiKTYxiRUE/vTi3u/+FwvpkqISIikg7DiIR2PHtryw04y5eIiGwAw4iEHOxavvwqLoBGREQ2gGFEYgvvGah3X6OKYYSIiDo+hhGJTYsJ1ruvUc3Fz4iIqONjGLEA90UE6tzOhViJiMgWMIxYgDnjB+jczp4RIiKyBQwjFqCrmwL9/dyabU/JLMG3B/IkqIiIiMh8GEYsxLqZw3Vuf37DEZy7VGXmaoiIiMyHYcRCONrr/09RXFFnxkqIiIjMi2HEQjg72Ondl19Wg399dQD7c0rNWBEREZF52EtdADWRyWR69z2zPgMAsON4Ec4tnmCmioiIiMyjXT0jy5YtQ3BwMJycnBAdHY39+/e32L6srAyzZ8+Gv78/FAoF+vbti61bt7arYCIiIupYDO4ZWb9+PeLj47F8+XJER0dj6dKlGDt2LDIzM+Hj49OsfX19PcaMGQMfHx9s2LABgYGBOH/+PDw9PY1RPxEREVk5g3tGlixZghkzZiAuLg6hoaFYvnw5XFxcsHLlSp3tV65cidLSUmzatAkjRoxAcHAwbrvtNoSFhd1w8R3NPeEBUpdARERkdgaFkfr6eqSnpyM2NvavE8jliI2NRVpams5jfvjhB8TExGD27Nnw9fXFoEGDsGjRIqhUKr3vU1dXB6VSqfWyBe89FC51CURERGZnUBi5dOkSVCoVfH19tbb7+vqisLBQ5zHZ2dnYsGEDVCoVtm7dildeeQXvvvsuXn/9db3vk5iYCA8PD80rKCjIkDKtllwug4uj/lk1AFDboD/EERERWSOTT+1Vq9Xw8fHBp59+isjISEyaNAlz587F8uXL9R6TkJCA8vJyzSsvz3ZWIVWpW35S711LU81UCRERkXkYNIDV29sbdnZ2KCoq0tpeVFQEPz8/ncf4+/vDwcEBdnZ//Yt/wIABKCwsRH19PRwdHZsdo1AooFAoDCmtw1CLlsPIucvV+CD5NGbd1qvFhdKIiIishUHfZo6OjoiMjERycrJmm1qtRnJyMmJiYnQeM2LECJw5cwbqax76lpWVBX9/f51BxNY9O6Zvq22WJGVhSVKWGaohIiIyPYP/aR0fH48VK1bgiy++wMmTJ/H444+jqqoKcXFxAIBp06YhISFB0/7xxx9HaWkpnn76aWRlZWHLli1YtGgRZs+ebbxP0YE8flsvzPtbaKvtvj94wQzVEBERmZ7B64xMmjQJJSUlmDdvHgoLCxEeHo7t27drBrXm5uZCLv8r4wQFBWHHjh149tlnMWTIEAQGBuLpp5/Giy++aLxP0YHIZDIM8HdvtV1rt3OIiIishUwIy/9WUyqV8PDwQHl5OdzdW/+itnYqtUCvOS2vUOvp4oCMeXeaqSIiIiLDtfX7myMgLZCdXP9zaq5qbdYNERGRtWAYsVIVtY1Sl0BERGQUDCMW6sDLsXgwspvUZRAREZkcw4iF8nZV4J2/h2HdzOF626h5q4aIiDoAhhELF9ylk959OZerzFgJERGRaTCMWDhVC5Odckurcd9Hv2Lr0QIzVkRERGRcDCMWzsdN/7L4cav+wKHcMjzx9UEzVkRERGRcDCMWzsGO/4mIiKhj4zcdERERSYphpINIzSqRugQiIqJ2YRixAnPHD2i1zf9+P2+GSoiIiIyPYcQKjOrftdU2O08UmaESIiIi42MYsQqtP6sGAEa/m4LfzlwycS1ERETGxTBiBbp7ubSp3dmSKkz5bJ+JqyEiIjIuhhEr4Ggvx91hAVKXQUREZBL2UhdAbfPuQ2Gwk8twb0QgFPZy/OPT3/W2rW1QwcnBzozVERERtR/DiJVwsJPjvUnhbWr79b5cPDoyxLQFERERGQlv03RAr/10QuoSiIiI2oxhxEo52rf8n25zxkUzVUJERHRjGEasVGuTfZ9el4H086UQLTz1l4iIyBIwjFgpRSs9IwDwwMdpCEnYig+ST5uhIiIiovZhGLFShnR4LEnKMl0hREREN4hhhIiIiCTFMGKlru0YGd3fR7I6iIiIbhTDiJWadFMQAODmXl1wU4iXxNUQERG1Hxc9s1Iv3NUPMT27YHivLvj69/NSl0NERNRu7BmxUgp7O8SG+sJVYY9/3NS91fbzNh8DAKjVAio1p/sSEZHlYBjpADxcHBDWzaPFNl+mnUdheS1GvLkL495PhZqBhIiILATDSAexOm5Yq22GJyajoLwWWUWVuFxVjx8O52Pb0QIzVEdERKQfx4x0EJ07ORrUvqy6Hv9eewgAkPn6XVDY8ym/REQkDfaMdCBxI4IBAIn3D261bUVdo+ZnjiEhIiIpMYx0IPMnDsSZN8Zh8rDu6Ovr2mLbhO+Oan7+49wVPsOGiIgkwzDSwdjbNf0nrWtUt9gus6hC8/P0lfuRklVi0rqIiIj0aVcYWbZsGYKDg+Hk5ITo6Gjs37+/TcetW7cOMpkM9957b3velgzQx6flnpHr7T5VbKJKiIiIWmZwGFm/fj3i4+Mxf/58HDx4EGFhYRg7diyKi1v+Mjt37hz+85//4JZbbml3sdR2i+5rfdwIERGRJTA4jCxZsgQzZsxAXFwcQkNDsXz5cri4uGDlypV6j1GpVJg6dSoWLFiAnj173lDB1DY+7k7ISRyPg6+MgYezQ6vt1+zLxa9nLml+5xgSIiIyF4PCSH19PdLT0xEbG/vXCeRyxMbGIi0tTe9xCxcuhI+PDx599NE2vU9dXR2USqXWiwwnk8ng1cmxTQucNaoFpn62DwCQdKIIUa//jF9OcxwJERGZnkFh5NKlS1CpVPD19dXa7uvri8LCQp3H7N27F59//jlWrFjR5vdJTEyEh4eH5hUUFGRImXSdv0e1/foJITDjywO4XFWPhz9v21ggIiKiG2HS2TQVFRV4+OGHsWLFCnh7e7f5uISEBJSXl2teeXl5Jqyy43vhrn545W+hbWobkrDVxNUQERFpM2gFVm9vb9jZ2aGoqEhre1FREfz8/Jq1P3v2LM6dO4eJEydqtqnVTVNO7e3tkZmZiV69ejU7TqFQQKFQGFIatcDJwQ6PjgzBaz+dMNo5TxUqcTivDA9FBUEmkxntvEREZHsM6hlxdHREZGQkkpOTNdvUajWSk5MRExPTrH3//v1x9OhRZGRkaF533303Ro0ahYyMDN5+MbPnxvS9oeN/O3sJz6w7hNKqety19Be8+N1R/HiEz7YhIqIbY/CzaeLj4zF9+nRERUVh2LBhWLp0KaqqqhAXFwcAmDZtGgIDA5GYmAgnJycMGjRI63hPT08AaLadTO+p0X3w45F8ZBVVtvmY8poGzWycKSuaBrhe2xNy/GI57g4LMG6hRERkUwweMzJp0iS88847mDdvHsLDw5GRkYHt27drBrXm5uaioID/WrZU62c278FqSdiCnSgor9HatvHQRc3PnABMREQ3SiasYEEJpVIJDw8PlJeXw93dXepyrN6afbmYs/Fo6w2vcWLhWITO29Fs+4xbQjB3QtsGxxIRkW1p6/c3n01jg6ZEd8f+uaMNOkZXECEiIjIGhhEb5ePmZJTzFCnrjHIeIiKyXQwjNuz/hne/4XP8cDgfAKBWC1yqZDAhIiLDGTybhjqO1+8djKDOLkjcduqGzvP8t4dxuaoeu04V47vHYxDZw8tIFRIRkS1gz4iNezimB8KCPG/oHN+mX8CuU01PbX7g4zSkZOp/gvPJAiVmf30QZ0vaPr2YiIg6NoYRG+fiaI/Ns0dobevp3emGzvnPVX8A0P3k34eWp2HL0QI8/OdD+YiIiBhGqJlNT45ovVErPkg+jZCErZj86e8Qomk8yYrUbFTUNQIA8strb/g9iIioY+CYEdLy2j0D4epoD69Ojiitqm/3eZYkZQEA0rIvo6pehbHvpeLyDZyPiIg6LvaMkJZeXV0hl8uwf85o9PdzM8o5R72TojOIbEi/gCsMKERENo89IwQAWPnPKGQVVSKmVxcAgL2dHPZ2xnkab0mF7im///n2MCJ7dMZ3j99slPchIiLrxDBCAIA7+vvijv6+WttcHP/688heNB5yuQxbjhRg9pqDRnvf9PNXjHYuIiKyTrxNQ3otvn8w+vi4YumkcMjlTb0k4wf7Gf19hBA4cqEMGw9dQE29yujnJyIiy8YH5ZHBhBC47e0U5JZWG/3ck4d1R+L9g41+XiIiMj8+KI9MRiaTYdPsERgWbPyVVr89kAcAOHKhDP/32T4cu1hu9PcgIiLLwjBC7eLVyRHfzIox+nkb1QKNKjXu/u+v2HvmEv7vcy6ORkTU0TGM0A3Z/swteHRkiFHP2XvuNs3PZdUN+MenaTiezx4SIqKOimNGyCguVdahSFmLYmUdbu7dBf1e3g4AmBgWgB//fLLvjfB0cUD6y2NwprgSfX1dIZMZZ9oxERGZTlu/vxlGyCRUaoFGtRoOcjl6ztlqlHPeGeqLnSeK8NjIELz8t1DEr89AobIW/3s0WjPbp6y6HhW1jQjycjHKexIRUftxACtJyk4ug8LeDnK5DJmv34W7wwJu+Jw7TxQBAD7bm4O80mp8f+gifjt7GScKlACAgvIahC9Mwi1v7UaRks++ISKyFgwjZHIKezu88/cwvPnAYBjr7sotb+3W/PzNnzNw5m8+rtl29ALHmBARWQuGETILR3s5Jt3UHbf06Wr0c3+Zdh6pWSWanhMAeH7DYQBNY1l0DX61gruTREQ2g2GEzKpRpTbJeaet3K/1+5XqBgBA1Os/Y8IHe3GqUKnZt2jrSYQkbMUPRhhYS0REN45hhMxKbcYeieCXtmh+vmvpL5jx5QF8eyAPn6ZmAwD+vfYQ1GqB/LIarNmXi9oGFbJLKvHkmoM4WaDUd1oiIjIyzqYhs8osrMDkFb9j9qjeeO2nE5rtD0Z2g7ODHb76/bxZ63lpXH8s33MWZdUNmHlrT+w4Xojzl6vh5CDHqdfGmbUWIqKOhlN7yWIJISCTyTB4/g5U1DUi1N8dW5++BQBQ26DCU2sPIema8R/m0s/XDZlFFZrfzy2eYPYaiIg6Ek7tJYt1dcGy7564GQ9FdcOn0yI1+5wc7LBiWpQkdV0bRABg1a852HjoAka9k4I1+3IlqYmIyBawZ4Qs0s7jhfjpSAGcHewwMSwAW48V4M5QX/xz1R+S1XRu8QQIIdCoFqhvVKOTwl6yWoiIrAFv01CHdO2gVCn09XVFeU0DipR1OPLqnXB1tEd1gwrD3vgZwV06Ycu/R7ZrqXohBAqVtfD3cDZB1URE0uBtGuqQ5ozvjwAPJ4wf7IcJQ/zx4eQIuJmxhyKrqBJFyjoAQEpmCaat3I9B83egul6FEwVKvLL5GJbvOYun1h6CSi1QWF6Lj1PO4kpVfbNzbc64iAc+/g2F5bV4LykLMYm7sOLPmT5ERLaEPSNk9SpqGzD41Z1Sl9Gi4C4uSHl+FOob1aisa4RXJ0dNL8/1DxP8Of5WlFU3ICrYS6pyiYiMgj0jZDPcnByQMK4/AEAmA9ycLG8sx7nL1ci5VIVR76Rg6GtJyC+r0exT1jRotY1dkooHl6fh7R2nUNugglpt8f9eICK6IewZoQ6hQaXG9mOFGBbiBR83BQ5fKMe9y34FAPxtiD9+OlIgcYXtF9WjM76dFYPiijr4ujtBCAFlTSM8XBzQoFIj/fwVhAd5orC8Fj26uLRrzEp7lVbVQ1nTgGDvTmZ7TyKyHiYdwLps2TK8/fbbKCwsRFhYGD788EMMGzZMZ9sVK1bgyy+/xLFjxwAAkZGRWLRokd72ujCMUHt8sucsZDLg/qHd8NSaQ/jHsCAsScrC+cvVUpdmsN4+rjhTXImn7uiNz37JQU2DCp88HImD56/gk2vGmcy8tSfmjB8AAKiqa4SLo53ecKJWC8jlNxZcrt5qSku4g4NviagZk92mWb9+PeLj4zF//nwcPHgQYWFhGDt2LIqLi3W2T0lJweTJk7F7926kpaUhKCgId955Jy5evGjoWxMZ5F+39cLMW3vB21WBtTOH457wQCybMlSzP/3lWAmrM8yZ4koAwIe7zqCmQQUA+NdX6VpBBIBmqfsfD+dj4Pwd+NdX6TrPV9ugwh3vpmD21wd17q+obYDKgNtDxy5y+Xwiaj+Dw8iSJUswY8YMxMXFITQ0FMuXL4eLiwtWrlyps/3XX3+NJ554AuHh4ejfvz8+++wzqNVqJCcn33DxRIYaFOiBc4sn4NziCejiqsDOZ29FTM8umv3rZw7Hd4/HwNnBDr7uCgkrbb8GlRpPrT0EAFpPMr5WalYJzl2uxpajBc2eYFxYXovBr+7EAx//1ub3vMEOFiKycQaFkfr6eqSnpyM29q9/UcrlcsTGxiItLa1N56iurkZDQwO8vDhTgKTX19cNXzwyDO//Ixz7545GdM8uiOzhhaOv3olfXrgDw3ta399pn7nbtH5XqwXW7MvF6T9XmK2sa8TRi+Wa/Z/vzcGJfCVe3nQUJRV1mpk9GXllet+jvlGN3Zl/9YZevd2Tc6kKi7aeRHFFrbE+jkHOFFfgxQ1HkFdqfbfiiGyZQdMOLl26BJVKBV9fX63tvr6+OHXqVJvO8eKLLyIgIEAr0Fyvrq4OdXV1mt+VSnYBk+k42stxT3ig1jZ7u6acvm5mDNRqgbMllejV1RXTV+3HxbIavPv3MDjayzHhg71SlGyQnnO2trj/9S0nNT//7/fmy97XNqjwQfJpxIb6Ymj3zli5NwcLr3nIIQBcrqzHpkMXMXfjUVTVq3DkQhnWzYwxzgcwwIPL01BW3YBDeVew89nbzP7+RNQ+Zp0DuXjxYqxbtw4pKSlwcnLS2y4xMRELFiwwY2VE+snlMvTxdQMAfPlI08Drq4NCzy2egCtV9Yh4LUnTfv7EUDSo1Mgvq8Xq386ZvV5juuOdFOSWVqNRLfBRyln09XVFVlFls3b/+faw1u8Hz5eZqUJtZdVN06R11UhElsug2zTe3t6ws7NDUZH2feiioiL4+fm1eOw777yDxYsXY+fOnRgyZEiLbRMSElBeXq555eXlGVImkcnIZLJms1M6d3LE4vsHAwBeu2cg4kaEYOatvfDK30Jxe7+uUpRpNNmXqtB4zUDWNn/Jy5qWuF//Ry5O5BvWs1lSUYdP9pzFpco6CCEw66t0PPbFgWZjW4io4zCoZ8TR0RGRkZFITk7GvffeCwCawahPPvmk3uPeeustvPHGG9ixYweiolp/IqtCoYBCYZ2DB8k2/WNYd0wY4g83JwfNNju5DKvjhuG79At47s+egyAvZ+SV1ug7TYdR36jGhvQLePG7owCAjHljMHfTMYwd6Ie7wwJQ26BCeU0DfN3/6iFNySzGnqwS7MsuxYkCJRZvPwV7uQwNqqYQUlJRBx/35j2qQoh2ra1SUduA7JIqDOnmYda1WYioOYNv08THx2P69OmIiorCsGHDsHTpUlRVVSEuLg4AMG3aNAQGBiIxMREA8Oabb2LevHlYs2YNgoODUVhYCABwdXWFq6urET8KkbSuDSLXeiCyGzLyyiCXAQvuGYTB83egoq4RXd0U+M+dfTVf2ABwb3gA3psUDplMhjPFFViRmoP1B6yzZ/D5DUc0P4cvbLqNteVIAUb29sZdS1NRXFGHxfcPxj+GdYdaLZo9kVkIaILItcqrG9BJYYdZ/zuIn08WIcS7E7b++xY4O9oZVN89//0V2ZeqsPz/InHXIP09u7UNKszffByxob4YE+qrt11Hk1VUgZV7c/DU6D4I9OQaMmRa7Vr07L///a9m0bPw8HB88MEHiI6OBgDcfvvtCA4OxurVqwEAwcHBOH/+fLNzzJ8/H6+++mqb3o+LnlFHUtugQl2jGh7ODprfnRz0f5E+uz4Dv565hOKKOr1trNnJhXfhzqV72tRjdH9EIL4/1HyNotfvHYT/G95D66nOj4wIweaMi5gS3R3jBvnjj3OlWJKUhX/eHIxnx/TVtB0/2A8fTY3U3Aa6vpdk2e4zeHtHJoCmMUK2ov8r21DboMaQbh744cmRUpdDVsqkK7CaG8MI2TohBBb+dAKrfj0HAFj1z5swLMQLv529jDkbm6bkUttlLxqvmWU0JtQX0SFemllFi+4bjCnR3TVtZ32Vju3Hm3p0184Yjm3HCvDCXf3h+ufTovdklaBX107o1tkFQNPtH1eFvdXf+rka1uQyIDvRdkIYGRfDCFEHU1BegzvfS8UDQ7vh1bsHau3bcqQARy6W4bkx/fDI6j/Qq2snfJHWvEeS2m7Lv0eitkGFBz5uvobSA0O74d2HwvDL6RI8/Pl+AMBjI0PQz88Nz284gjtDffHptNbHx5lCo0qNQmWtJhy1x5ELZbj7v79qfjdWj1BtgwoPf74PI3t3xdOxfYxyTrJsDCNEHVCjSq1ZA6U1lyvr8NiXB3AotwwA8OrEUIzq7wMXR3s4O9ph6mf7EBHkiYraRmTkXcHZkioTVm59/D2cUFCuf/G2Pj6u8OrkiH05pTr3n3ljHC5X1cPTxQEK+7aNZ7n+eUEfJp/G+8mnseeFUW0etxG3aj92Z5bgrQeH4MGh3Qx+/lBheS2GJ2qvkN1aGDlZoISbk32rAWjNvlzM2Xi0TeekjqGt39+W96x1ItKrrUEEALq4KrDxiRG4XFkHVyf7Zl+Im2eP0Po94fujWLs/F3PG90eApzPSzl7GgrsHoqpehRWp2fBwdsAbW5tuZcQO8MXPJ3UvNd9RtBREAOB0ccvTnHtfsxLuwAB3rHlsOPLLa7DtWCHibg6GXC7Dw5/vg4ezAz6aOhSLt53CtmOFcHOyR1QPL7z7UBjeTcoCAIx6OwXHFozFhvQL6Nm1E3p1dUVnFwedfw+7M0sAAC9sOILdp4rx8f9FGvS5cy4ZFkqLlLUY9/4vAFoPGHWNKoPOTbaDYYSog+vi2rZp8on3D0bin+ulAMDfhgQAADyc5fjP2H4AgBDvTli7PxeL7h+En99oCiP754zGS98fxa5Tuh+WScDxfCXCFu7U/H66qALbjhVqfh/86l/7Sqvqcf5yNd5+8K/1mOpVavx312l8sOuMZluQlzN+eeEOze/l1Q04d1k7SGw7VoiPU84iskdnHLlQhnGD/bHrZBGO5yvxxn2DYSeXYfepYny+NwdvPTgEAZ7OsDOwJ+VsSdsXmJNfN45GCIHj+Ur08XVtc++RNckrrcbzGw5j5q09cUf/ts3EUqsF/r3uEPr7ueHJO/66laVSC4P/21gThhEiarPYUF/E/jm9df+c0WhQC/i4O2HlP2/SmslylZvCHnteGIVTBUq8uSMTh1t43o0tuTaI6LM0+bTW79cGEQDIK63RuubdvVyQq+OZPG9u/+tRHdcu/d+gEriljzeeWZ8BALh58S6cWDi2Tc8VOpR7Bfd99Bteu2egZnVioOkWz4Ur1Yjs0VnnAN5rN331+3kIITBv83GM6tcVq+KGtfq+V7V3bZlr1TaosHjbKdzWrytG9fO5oXPpk/D9UfyeXYrfs0v19hpdf+t175lL+OlIAX46UqAJI6cKlXjw4zQ8fnsvzB7V2yS1So1hhIjaRdcCZFclP3cbkk8WYVpMMJwc7HBzb29s7u2t+fL89+g+eOqO3sjIK0P8Nxk2sRCcoT64Loy0RlcQacl3By/gu4MXtLY99Ekajl1svmJuWXU97OQynCyowMyvDmiW3X9l83H09f1rvairY03kMuDEwrugrG2Aj5sTMvLKkF9Wg2vjwyubjsHb1RHAX7eWrlXXqEJ+WS2SThQiNesSPpveNCD42MVyPLnmEB67JQSeLo4I6+aBPr5u+PFwPjakX8D7/whHVlEldp0qxrNj+ujtcXnxuyPYnJGP1b+dazaDylC1DSpM+vR33NSjM17+W6hme2u9Riv35mDxtlP4ekY0bgpueihnZV1js3YLfzyByrpGvL0jU28YEUIgcdsp9PN1wwOR3dr9WaTCAaxEZBQHzpVi1v/Ssf5fMejVVfeChlfDyPL/G4q7BvkDaPqf6O/ZpRjg74biijqs/yMPcSOCNYMhhRDYl1OK7w9ewN1hgci+VIkT+UokjB+A5JNFiP/msM73Isvwyt9C8dp1D1bU5ef4W/HD4QJMje4OX3cn3PfRr5rB1wCw8J6B+Gj3WRQqm/fcnFs8QfO39c+bg5s9E+rh4T2w4O6Bmp4ZmUymsydvTKgvahtUGDfIH3+P6gaHP3ssymsa8O2BPIwJ9cWcjUdxU7AXZt7aEy6O9hBCoPfcbVD9+diEqz0gB86V4sHlf83EGtnbG5//M0orHF2toUcXF+x+7nbI5TL8eDgfT609pDlXg0qt9STuX1+6Axm5ZRg3yA+5pdWQyYAeXTohNasE01Y2zew68HIsHvz4NzwwtBueGi3trCXOpiEii5N+/goy8srwyIhgo63DUV7TAHcne9Q2qDF7zUFMi+mhWc3V3ckeytpGBHg4Ib+VAalkvRT2ctQ1qgEA/f3ccKqwQm/bAf7umDDYD+/szGrxnEO7e2LppAhcqqrD/R/9pvdcJwu0e5KuhhFdYeedv4fhwWt6LfS1ufrgyXOLJ2BJUpbOXrIFdw/E/B+OAwD+mBuLm974WbPv0ZEh+HxvDgBgxbQozN98DO9NCkd0zy64XFmH7EtViOrRGbUNaoNXLjYUwwgR2bT6RjWq6xux8dBFTAwLQJdOjnhnZyaW7T4LAEhLuAP+Hs64VFmH1346gc0Z+QCAn54aiW3HCrD9WCHOllThyVG98d/dZ1p6KyKNiWEBiB3gg6fXZTTb96/beiJh3ABU1TXCxdEOIQlbWzzXN/+KwUOfNF/npjXTYnrgSx3rDJ1bPAF95m7VeszCG/cNwtToHga/R1sxjBARXUcIgY2HLiIsyFPvrSRdPt+bgy/TzmHNjOHYl30ZG9Iv4Lezl7XaPHVHb0y/ORhxq/7A0Yvlxi6d6IY9FNUN3xy4oHPfhMH+WDZ1qNHfk2GEiMhEKmobMG/zcQwK9EBVXSNC/d1xW7+umjEGQFPwuVhWg5Fv7kZkj864uVcXfLjrDJY8FIZNGflIzSrBbX27okGlxtePRev8V/IzsX2w43hRs1sBRKZwdtF4o08fZhghIrIAZdX1cFXYw95OjtKqenh1ctTZbk9WCV776QR6d3XF9uOFeHRkCF68qz9q6lVY9VsOenV11QxsPLFwLEoq6nDb2yma4zNfvwv9Xt6u89xLHgpDbKgvFv54ArEDfFDXqMZb2zNxsYyzmOgv62YOx/CeXYx6Tq7ASkRkATxd/gof+oIIANzWtytui7+t2XZHezmeie0LlVpg/R958HV3goujPXp0scfdYQH44XDTWBeFvR0mDwtCflktlv9fJDKLKpCSWYzJw5pmpwBNgyOvuic8EKcKlXC0k6O7lwuW7T6LEb27YFCgB3JLq+HsYIdb3toNAHBykKO2Qa1V17nFE/Cvrw5gx/EirHksGh4uDpjwwV4AwKh+XfHcnf3wtw/3tvOqkRTSz18xehhpK/aMEBFZqdKqeryXlIW/R3XDkG6eRj9/ZV0jnB3sNNOvw7t74tczlzDAzx3duzRNva6pV2nNyGhQqTW3qy5V1uHljcew/Xgh+vm6IbOoaZZLkJczipV1mhkw14ad/XNG476PftP02oT6u+PEdbepPF0cEDvAFxvSdY9/oPZ5Nrav0R9gyNs0RERkEeob1XC0b/m5SmeKK+Dp4gjvPx9fsGRnJhQOdi0u8qWsbcT+nFLM3XgU028OxhO399JMGX//59N47+em6btvPjAY4UGdMXZpqub4F+/qj2/T8/DmA0PQw8sFDnZyHMsvx3PfHIa9XIZJN3WHn4cCL353FBtmxaC/vzu+S7+Awd089E71ffOBwXjxu6MGXx9LsWJaFMaEtm3Z+rZiGCEiIrrGiXwlvN0c4eXiaNBDJ6+nUgvc/s5u5JXWYNU/b8Lt/boCgCYIldc0YNepIgwK8MCY95oC0AeTIzCiVxdsSL+AxG2ndJ737QeHoLtXU4/T0p9PIy37Mu4M9cXbD4Zh+/ECzNt8XNObdL054/vj3vBAVNercPs7Ke36XDmJ4422/s9VDCNEREQmVNeoavUBf2q1gEz2V1AprqjFsDeals0fFOiOd/8ejn5+bqiub4SLo73WcWdKKtG7qyvk18xw2ZNVgi9/O4fkU8UIC/LES3f1x/CeXq2GCCEEGlQC93/8K45dVOKWPt4YFOiBiUMC4OJoh26dnW8ooOnDMEJERGSBdh4vhKvCHjf39m73OVRqAfk1IaetlLUNOHahHMN7dtEKOabC2TREREQW6M6Bfjd8jvauB+Lu5HBDIchUjN8nQ0RERGQAhhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkrKKp/YKIQA0PYqYiIiIrMPV7+2r3+P6WEUYqaioAAAEBQVJXAkREREZqqKiAh4eHnr3y0RrccUCqNVq5Ofnw83NDTKZzGjnVSqVCAoKQl5eHtzd3Y12XmqO19o8eJ3Ng9fZPHidzcOU11kIgYqKCgQEBEAu1z8yxCp6RuRyObp162ay87u7u/MP3Ux4rc2D19k8eJ3Ng9fZPEx1nVvqEbmKA1iJiIhIUgwjREREJCmbDiMKhQLz58+HQqGQupQOj9faPHidzYPX2Tx4nc3DEq6zVQxgJSIioo7LpntGiIiISHoMI0RERCQphhEiIiKSFMMIERERScqmw8iyZcsQHBwMJycnREdHY//+/VKXZNFSU1MxceJEBAQEQCaTYdOmTVr7hRCYN28e/P394ezsjNjYWJw+fVqrTWlpKaZOnQp3d3d4enri0UcfRWVlpVabI0eO4JZbboGTkxOCgoLw1ltvmfqjWYzExETcdNNNcHNzg4+PD+69915kZmZqtamtrcXs2bPRpUsXuLq64oEHHkBRUZFWm9zcXEyYMAEuLi7w8fHB888/j8bGRq02KSkpGDp0KBQKBXr37o3Vq1eb+uNZlI8//hhDhgzRLPQUExODbdu2afbzOhvf4sWLIZPJ8Mwzz2i28Tobx6uvvgqZTKb16t+/v2a/xV9nYaPWrVsnHB0dxcqVK8Xx48fFjBkzhKenpygqKpK6NIu1detWMXfuXPH9998LAGLjxo1a+xcvXiw8PDzEpk2bxOHDh8Xdd98tQkJCRE1NjabNXXfdJcLCwsTvv/8ufvnlF9G7d28xefJkzf7y8nLh6+srpk6dKo4dOybWrl0rnJ2dxSeffGKujympsWPHilWrVoljx46JjIwMMX78eNG9e3dRWVmpaTNr1iwRFBQkkpOTxYEDB8Tw4cPFzTffrNnf2NgoBg0aJGJjY8WhQ4fE1q1bhbe3t0hISNC0yc7OFi4uLiI+Pl6cOHFCfPjhh8LOzk5s377drJ9XSj/88IPYsmWLyMrKEpmZmWLOnDnCwcFBHDt2TAjB62xs+/fvF8HBwWLIkCHi6aef1mzndTaO+fPni4EDB4qCggLNq6SkRLPf0q+zzYaRYcOGidmzZ2t+V6lUIiAgQCQmJkpYlfW4Poyo1Wrh5+cn3n77bc22srIyoVAoxNq1a4UQQpw4cUIAEH/88YemzbZt24RMJhMXL14UQgjx0Ucfic6dO4u6ujpNmxdffFH069fPxJ/IMhUXFwsAYs+ePUKIpmvq4OAgvv32W02bkydPCgAiLS1NCNEUGuVyuSgsLNS0+fjjj4W7u7vmur7wwgti4MCBWu81adIkMXbsWFN/JIvWuXNn8dlnn/E6G1lFRYXo06ePSEpKErfddpsmjPA6G8/8+fNFWFiYzn3WcJ1t8jZNfX090tPTERsbq9kml8sRGxuLtLQ0CSuzXjk5OSgsLNS6ph4eHoiOjtZc07S0NHh6eiIqKkrTJjY2FnK5HPv27dO0ufXWW+Ho6KhpM3bsWGRmZuLKlStm+jSWo7y8HADg5eUFAEhPT0dDQ4PWde7fvz+6d++udZ0HDx4MX19fTZuxY8dCqVTi+PHjmjbXnuNqG1v9+1epVFi3bh2qqqoQExPD62xks2fPxoQJE5pdC15n4zp9+jQCAgLQs2dPTJ06Fbm5uQCs4zrbZBi5dOkSVCqV1kUHAF9fXxQWFkpUlXW7et1auqaFhYXw8fHR2m9vbw8vLy+tNrrOce172Aq1Wo1nnnkGI0aMwKBBgwA0XQNHR0d4enpqtb3+Ord2DfW1USqVqKmpMcXHsUhHjx6Fq6srFAoFZs2ahY0bNyI0NJTX2YjWrVuHgwcPIjExsdk+XmfjiY6OxurVq7F9+3Z8/PHHyMnJwS233IKKigqruM5W8dReIls0e/ZsHDt2DHv37pW6lA6rX79+yMjIQHl5OTZs2IDp06djz549UpfVYeTl5eHpp59GUlISnJycpC6nQxs3bpzm5yFDhiA6Oho9evTAN998A2dnZwkraxub7Bnx9vaGnZ1ds5HERUVF8PPzk6gq63b1urV0Tf38/FBcXKy1v7GxEaWlpVptdJ3j2vewBU8++SR++ukn7N69G926ddNs9/PzQ319PcrKyrTaX3+dW7uG+tq4u7tbxf+4jMXR0RG9e/dGZGQkEhMTERYWhvfff5/X2UjS09NRXFyMoUOHwt7eHvb29tizZw8++OAD2Nvbw9fXl9fZRDw9PdG3b1+cOXPGKv6ebTKMODo6IjIyEsnJyZptarUaycnJiImJkbAy6xUSEgI/Pz+ta6pUKrFv3z7NNY2JiUFZWRnS09M1bXbt2gW1Wo3o6GhNm9TUVDQ0NGjaJCUloV+/fujcubOZPo10hBB48sknsXHjRuzatQshISFa+yMjI+Hg4KB1nTMzM5Gbm6t1nY8ePaoV/JKSkuDu7o7Q0FBNm2vPcbWNrf/9q9Vq1NXV8TobyejRo3H06FFkZGRoXlFRUZg6darmZ15n06isrMTZs2fh7+9vHX/PNzwE1kqtW7dOKBQKsXr1anHixAkxc+ZM4enpqTWSmLRVVFSIQ4cOiUOHDgkAYsmSJeLQoUPi/PnzQoimqb2enp5i8+bN4siRI+Kee+7RObU3IiJC7Nu3T+zdu1f06dNHa2pvWVmZ8PX1FQ8//LA4duyYWLdunXBxcbGZqb2PP/648PDwECkpKVpT9KqrqzVtZs2aJbp37y527dolDhw4IGJiYkRMTIxm/9UpenfeeafIyMgQ27dvF127dtU5Re/5558XJ0+eFMuWLbO5qZAvvfSS2LNnj8jJyRFHjhwRL730kpDJZGLnzp1CCF5nU7l2No0QvM7G8txzz4mUlBSRk5Mjfv31VxEbGyu8vb1FcXGxEMLyr7PNhhEhhPjwww9F9+7dhaOjoxg2bJj4/fffpS7Jou3evVsAaPaaPn26EKJpeu8rr7wifH19hUKhEKNHjxaZmZla57h8+bKYPHmycHV1Fe7u7iIuLk5UVFRotTl8+LAYOXKkUCgUIjAwUCxevNhcH1Fyuq4vALFq1SpNm5qaGvHEE0+Izp07CxcXF3HfffeJgoICrfOcO3dOjBs3Tjg7Owtvb2/x3HPPiYaGBq02u3fvFuHh4cLR0VH07NlT6z1swSOPPCJ69OghHB0dRdeuXcXo0aM1QUQIXmdTuT6M8Dobx6RJk4S/v79wdHQUgYGBYtKkSeLMmTOa/ZZ+nWVCCHHj/StERERE7WOTY0aIiIjIcjCMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkxTBCREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJKn/B/ZNyHcyVMFgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lds_loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.4419136047363281\n",
      "Epoch 100, Loss: 1.0724997520446777\n",
      "Epoch 200, Loss: 0.915723443031311\n",
      "Epoch 300, Loss: 0.7774035930633545\n",
      "Epoch 400, Loss: 0.5696555376052856\n",
      "Epoch 500, Loss: 0.4693268835544586\n",
      "Epoch 600, Loss: 0.39263835549354553\n",
      "Epoch 700, Loss: 0.3419053554534912\n",
      "Epoch 800, Loss: 0.29540884494781494\n",
      "Epoch 900, Loss: 0.25768083333969116\n",
      "Epoch 1000, Loss: 0.23699259757995605\n",
      "Epoch 1100, Loss: 0.24736440181732178\n",
      "Epoch 1200, Loss: 0.20291151106357574\n",
      "Epoch 1300, Loss: 0.2295498549938202\n",
      "Epoch 1400, Loss: 0.19499915838241577\n",
      "Epoch 1500, Loss: 0.19440096616744995\n",
      "Epoch 1600, Loss: 0.17665520310401917\n",
      "Epoch 1700, Loss: 0.1843705028295517\n",
      "Epoch 1800, Loss: 0.17995813488960266\n",
      "Epoch 1900, Loss: 0.15582576394081116\n",
      "Epoch 2000, Loss: 0.1777338683605194\n",
      "Epoch 2100, Loss: 0.15578609704971313\n",
      "Epoch 2200, Loss: 0.17148280143737793\n",
      "Epoch 2300, Loss: 0.1693827211856842\n",
      "Epoch 2400, Loss: 0.13806907832622528\n",
      "Epoch 2500, Loss: 0.16049686074256897\n",
      "Epoch 2600, Loss: 0.14039641618728638\n",
      "Epoch 2700, Loss: 0.13913768529891968\n",
      "Epoch 2800, Loss: 0.1715879738330841\n",
      "Epoch 2900, Loss: 0.1458459198474884\n",
      "Epoch 3000, Loss: 0.12398131936788559\n",
      "Epoch 3100, Loss: 0.1296597719192505\n",
      "Epoch 3200, Loss: 0.13642525672912598\n",
      "Epoch 3300, Loss: 0.14190885424613953\n",
      "Epoch 3400, Loss: 0.12169083952903748\n",
      "Epoch 3500, Loss: 0.12095183879137039\n",
      "Epoch 3600, Loss: 0.14964847266674042\n",
      "Epoch 3700, Loss: 0.11091169714927673\n",
      "Epoch 3800, Loss: 0.1028403639793396\n",
      "Epoch 3900, Loss: 0.1231999397277832\n",
      "Epoch 4000, Loss: 0.12759371101856232\n",
      "Epoch 4100, Loss: 0.13106848299503326\n",
      "Epoch 4200, Loss: 0.12604597210884094\n",
      "Epoch 4300, Loss: 0.12321901321411133\n",
      "Epoch 4400, Loss: 0.11889061331748962\n",
      "Epoch 4500, Loss: 0.12514261901378632\n",
      "Epoch 4600, Loss: 0.14915937185287476\n",
      "Epoch 4700, Loss: 0.12532465159893036\n",
      "Epoch 4800, Loss: 0.11569595336914062\n",
      "Epoch 4900, Loss: 0.11773215234279633\n"
     ]
    }
   ],
   "source": [
    "state_dim = 100 #@param\n",
    "lds2 =  LDS(state_dim, n_embd, n_embd).to(device)\n",
    "optimizer = torch.optim.Adam(lds2.parameters(), lr = 0.0001)\n",
    "lds_epochs = 5000\n",
    "lds_loss_values2 = []\n",
    "\n",
    "for epoch in range(lds_epochs):\n",
    "    inputs = torch.randn(1, sl, n_embd).to(device)\n",
    "    stu_outputs = stu_layers[1](inputs)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = lds2.compute_loss(inputs, stu_outputs)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(lds2.parameters(), max_norm=1)\n",
    "    lds_loss_values2.append(loss.item())\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lds2.A.data.clamp_(max=1, min = -1)\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bfb6d40d00>]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lds_loss_values2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSSM(\n",
       "  (loss_fn): MSELoss()\n",
       "  (emb): Linear(in_features=24, out_features=8, bias=False)\n",
       "  (stu): ModuleDict(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (hidden): ModuleList(\n",
       "      (0-1): 2 x Block(\n",
       "        (rn_1): RMSNorm((8,), eps=None, elementwise_affine=True)\n",
       "        (stu): LDS()\n",
       "        (rn_2): RMSNorm((8,), eps=None, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (swiglu): SwiGLU(\n",
       "            (w): Linear(in_features=8, out_features=32, bias=False)\n",
       "            (v): Linear(in_features=8, out_features=32, bias=False)\n",
       "            (w2): Linear(in_features=32, out_features=8, bias=False)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (task_head): Linear(in_features=8, out_features=18, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = copy.deepcopy(model)\n",
    "\n",
    "model2.stu['hidden'][0].stu = lds\n",
    "model2.stu['hidden'][1].stu = lds2\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2624, -0.7246,  0.3471,  ...,  1.0012,  0.4601, -0.4034],\n",
       "         [-0.6449, -0.7182, -0.2634,  ...,  0.2590,  0.2195,  0.4972],\n",
       "         [-0.1447,  0.2504, -0.1133,  ...,  0.7784,  0.9955,  0.6227],\n",
       "         ...,\n",
       "         [-0.3076,  0.8855,  1.0127,  ...,  0.7641,  2.2225, -1.1648],\n",
       "         [-0.2089,  0.1288, -0.2712,  ...,  1.0472, -0.2887,  0.7433],\n",
       "         [ 1.3170, -1.0908, -0.9500,  ..., -0.4566,  2.0650,  0.2171]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randn(1, sl, n_embd).to(device)\n",
    "stu_layers[0](inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3576, -0.6357,  0.2724,  ...,  1.0767,  0.7188, -0.4107],\n",
       "         [-0.6701, -0.5868, -0.2437,  ...,  0.2022,  0.3057,  0.5920],\n",
       "         [-0.0791,  0.3482, -0.1158,  ...,  0.7745,  0.8273,  0.3588],\n",
       "         ...,\n",
       "         [-0.5752,  0.7120,  0.7838,  ...,  0.6912,  1.8403, -0.7535],\n",
       "         [-0.4688, -0.1015, -0.2222,  ...,  1.0850, -0.5169,  0.7119],\n",
       "         [ 0.9299, -1.1773, -0.3583,  ..., -0.4532,  1.5604, -0.0444]]],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lds(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 703/703 [02:35<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.9756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "def evaluate_model(model, val_loader, loss_fn, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():  # Ensure no gradients are calculated during validation\n",
    "        for val_inputs, val_targets in tqdm.tqdm(val_loader):\n",
    "            val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            loss, _ = loss_fn(val_outputs, val_targets)  # Assume metrics return is not needed here\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_loader)  # Average the validation loss\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "validation_loss = evaluate_model(model2, val_loader, loss_fn, device)\n",
    "print(f\"Validation Loss: {validation_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adagrad(model2.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 0.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9731.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 5.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9672.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 10.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9631.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 15.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9604.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 20.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9583.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 25.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9567.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 30.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9552.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 35.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9539.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 40.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9528.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 45.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9518.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 50.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9509.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 55.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9502.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 60.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9493.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 65.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9485.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 70.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9479.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 75.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9473.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 80.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9466.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 85.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9461.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 90.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9456.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 95.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9451.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 100.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9446.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 105.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9440.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 110.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9435.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 115.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9432.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 120.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9428.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 125.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9423.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 130.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9419.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 135.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9415.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 140.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9410.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 145.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9407.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 150.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9403.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 155.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9400.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 160.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9397.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 165.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9394.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 170.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9391.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 175.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9388.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 180.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9385.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 185.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9382.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 190.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9379.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 195.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9377.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 200.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9374.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 205.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9372.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 210.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9369.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 215.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9367.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 220.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9364.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 225.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9362.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 230.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9360.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 235.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9358.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 240.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9355.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 245.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9354.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 250.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9352.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 255.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9349.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 260.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9347.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 265.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9345.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 270.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9343.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 275.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9341.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 280.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9339.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 285.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9338.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 290.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9336.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 295.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9334.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 300.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9333.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 305.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9331.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 310.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9330.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 315.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9328.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 320.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9326.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 325.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9325.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 330.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9323.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 335.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9321.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 340.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9320.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 345.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9319.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 350.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9318.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 355.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9316.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 360.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9314.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 365.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9313.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 370.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9312.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 375.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9311.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 380.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9310.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 385.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9309.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 390.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9307.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 395.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9306.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 400.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9305.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 405.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9303.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 410.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9302.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 415.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9301.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 420.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9300.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 425.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9299.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 430.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9297.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 435.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9296.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 440.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9295.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 445.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9294.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 450.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9293.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 455.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9292.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 460.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9291.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 465.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9290.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 470.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9289.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 475.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9288.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 480.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9287.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 485.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9286.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 490.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9286.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 495.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9284.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 500.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9284.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 505.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9283.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 510.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9282.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 515.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9281.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 520.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9280.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 525.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9279.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 530.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9278.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 535.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9278.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 540.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9277.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 545.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9275.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 550.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9274.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 555.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9274.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 560.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9273.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 565.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9272.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 570.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9271.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 575.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9271.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 580.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9270.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 585.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9269.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 590.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9268.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 595.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9268.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 600.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9267.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 605.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9266.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 610.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9265.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 615.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9264.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 620.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9264.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 625.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9263.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 630.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9262.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 635.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9261.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 640.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9261.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 645.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9260.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 650.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9260.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 655.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9259.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 660.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9258.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 665.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9257.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 670.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9257.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 675.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9256.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 680.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9256.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 685.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9255.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 690.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9254.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 695.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9253.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 700.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9253.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 705.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9252.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 710.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9251.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 715.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9251.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 720.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9250.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 725.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9250.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 730.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9249.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 735.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9248.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 740.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9248.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 745.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9247.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 750.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9247.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 755.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9246.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 760.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9246.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 765.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9245.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 770.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9244.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 775.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9244.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 780.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9243.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 785.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9243.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 790.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9242.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 795.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9242.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 800.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9241.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 805.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9241.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 810.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9240.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 815.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9240.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 820.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9239.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 825.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9238.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 830.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9238.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 835.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9238.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 840.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9237.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 845.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9237.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 850.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9236.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 855.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9236.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 860.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9235.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 865.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9235.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 870.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9234.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 875.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9234.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 880.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9233.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 885.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9233.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 890.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9232.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 895.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9232.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 900.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9231.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 905.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9230.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 910.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9230.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 915.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9229.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 920.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9229.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 925.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9228.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 930.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9228.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 935.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9227.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 940.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9227.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 945.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9226.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 950.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9226.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 955.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9226.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 960.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9225.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 965.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9225.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 970.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9224.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 975.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9224.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 980.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9223.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 985.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9223.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 990.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9222.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 995.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9222.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1000.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9221.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1005.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9221.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1010.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9220.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1015.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9220.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1020.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9219.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1025.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9219.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1030.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9218.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1035.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9218.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1040.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9218.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1045.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9217.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1050.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9217.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1055.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9216.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1060.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9216.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1065.\u001b[0m\n",
      "\u001b[96m\n",
      "Validation Loss: 0.9215.\u001b[0m\n",
      "\u001b[96m\n",
      "Evaluating the spectral SSM model at step 1070.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [9:01:18<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[328], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m val_inputs, val_targets \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[0;32m     33\u001b[0m     val_inputs, val_targets \u001b[38;5;241m=\u001b[39m val_inputs\u001b[38;5;241m.\u001b[39mto(device), val_targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 34\u001b[0m     val_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     loss, metrics \u001b[38;5;241m=\u001b[39m loss_fn(val_outputs, val_targets) \n\u001b[0;32m     36\u001b[0m     val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\devan\\anaconda3\\envs\\sssm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\devan\\anaconda3\\envs\\sssm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[47], line 215\u001b[0m, in \u001b[0;36mSSSM.forward\u001b[1;34m(self, inputs, targets)\u001b[0m\n\u001b[0;32m    212\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstu\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstu\u001b[38;5;241m.\u001b[39mhidden:\n\u001b[1;32m--> 215\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_head(x)\n\u001b[0;32m    219\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(preds, targets) \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\devan\\anaconda3\\envs\\sssm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\devan\\anaconda3\\envs\\sssm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[47], line 147\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03mForward pass of the Block.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03m    torch.Tensor: Output tensor\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Good configuration\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrn_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrn_2(x))\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Basic configuration (no skips, no non-linearities)\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# x = self.stu(x)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\devan\\anaconda3\\envs\\sssm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\devan\\anaconda3\\envs\\sssm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[193], line 27\u001b[0m, in \u001b[0;36mLDS.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     25\u001b[0m     u_t \u001b[38;5;241m=\u001b[39m inputs[:, t, :]  \u001b[38;5;66;03m# Get input for all batches at time t\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     h_t \u001b[38;5;241m=\u001b[39m A \u001b[38;5;241m*\u001b[39m h_t \u001b[38;5;241m+\u001b[39m u_t \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB  \u001b[38;5;66;03m# Update hidden states for all batches\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     y_t \u001b[38;5;241m=\u001b[39m h_t \u001b[38;5;241m@\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m \u001b[38;5;241m+\u001b[39m u_t \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD \u001b[38;5;241m+\u001b[39m y_t \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM  \u001b[38;5;66;03m# Compute output for all batches\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(y_t\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Unsqueeze to preserve the sequence dimension\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\devan\\anaconda3\\envs\\sssm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1918\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1909\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m   1911\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[1;32m-> 1918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m   1920\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2.train()\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    for step, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs,  targets = inputs.to(device), targets.to(device)\n",
    "        relative_step = epoch * steps_per_epoch + step\n",
    "        last_step = relative_step == num_steps - 1\n",
    "        # print(inputs.shape,  targets.shape)\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model2(inputs)\n",
    "        loss,  metrics = loss_fn(outputs, targets)  # Assuming `loss_function` is defined\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        # Backward pass and optimization step\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model2.parameters(), 1.0)  # Clip global norm of gradient at 1.0, per the GPT-3 paper\n",
    "        grad_norms.append(grad_norm.item())\n",
    "        optimizer.step()\n",
    "\n",
    "        # Periodically evaluate the model on validation set\n",
    "        if relative_step % 5 == 0 or last_step:\n",
    "            colored_print(\n",
    "                f\"\\nEvaluating the spectral SSM model at step {relative_step}.\",\n",
    "                Colors.OKCYAN,\n",
    "            )\n",
    "            model2.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0.0\n",
    "                for val_inputs, val_targets in val_loader:\n",
    "                    val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n",
    "                    val_outputs = model2(val_inputs)\n",
    "                    loss, metrics = loss_fn(val_outputs, val_targets) \n",
    "                    val_loss += loss.item()\n",
    "                val_loss /= len(val_loader)\n",
    "                val_losses.append(val_loss)\n",
    "                val_time_steps.append(relative_step)\n",
    "            model2.train()\n",
    "\n",
    "            colored_print(\n",
    "                f\"\\nValidation Loss: {val_loss:.4f}.\",\n",
    "                Colors.OKCYAN,\n",
    "            )\n",
    "\n",
    "    if patient_counter >= patience:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
